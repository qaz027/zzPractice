{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60b5aa7b",
   "metadata": {},
   "source": [
    "# Lesson: Mounting an MCP Server in a FastAPI ASGI Application\n",
    "Introduction & Overview\n",
    "\n",
    "Welcome back! In the last two lessons, you learned how to connect your agent to one or more MCP servers, giving it access to a wide range of tools and services. You saw how tool caching can make your agent more efficient and how connecting to multiple MCP servers allows your agent to coordinate complex tasks — like managing a shopping list and placing orders — across different services.\n",
    "\n",
    "In this lesson, we will take your skills a step further by showing you how to combine your MCP server with a modern web framework using ASGI. Specifically, you will learn how to mount your MCP server inside a FastAPI application. This approach lets you serve your MCP tools alongside other web endpoints, making your application more flexible and scalable. By the end of this lesson, you will be able to run your MCP server as part of a FastAPI app, ready to handle both standard API requests and agent tool calls — all in one place.\n",
    "Overview of ASGI and FastAPI Essentials\n",
    "\n",
    "Before we dive into the code, let’s quickly review what ASGI and FastAPI are and why they matter for your projects.\n",
    "\n",
    "ASGI stands for Asynchronous Server Gateway Interface. It is a modern standard for Python web servers and applications, designed to support asynchronous programming. This means your application can handle many requests at the same time without waiting for each one to finish before starting the next. This is especially useful for real-time features, streaming, and high-concurrency workloads.\n",
    "\n",
    "FastAPI is a popular ASGI framework that makes it easy to build fast, modern web APIs in Python. It is built on top of Starlette and uses Python’s async features to deliver high performance. FastAPI is known for its simple syntax, automatic documentation, and support for both synchronous and asynchronous code.\n",
    "\n",
    "By combining your MCP server with FastAPI, you get the best of both worlds: the ability to serve your agent tools and regular web endpoints together, and the performance benefits of asynchronous programming.\n",
    "FastAPI and Uvicorn Setup\n",
    "\n",
    "If you are working on your own machine, you would typically install Uvicorn and FastAPI using pip:\n",
    "\n",
    "Bash\n",
    "\n",
    "pip install fastapi uvicorn\n",
    "\n",
    "However, on CodeSignal, these libraries are already installed for you, so you can focus on writing and running your code without worrying about setup.\n",
    "Mounting an MCP Server Within FastAPI\n",
    "\n",
    "Let’s look at how you can mount your MCP server inside a FastAPI application. Below is a simplified version of the code you will work with:\n",
    "\n",
    "Python\n",
    "\n",
    "import uvicorn\n",
    "\n",
    "from fastapi import FastAPI\n",
    "\n",
    "from shopping_list import ShoppingListService\n",
    "\n",
    "from mcp_server import mcp  # Import the MCP server with the shopping list tools\n",
    "\n",
    "\n",
    "# Create the FastAPI app\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "\n",
    "# Create a shopping list service instance\n",
    "\n",
    "shopping_list = ShoppingListService()\n",
    "\n",
    "\n",
    "# Regular FastAPI route for getting all shopping list items\n",
    "\n",
    "@app.get(\"/items/\")\n",
    "\n",
    "async def get_all_items():\n",
    "\n",
    "    \"\"\"Get all shopping list items.\"\"\"\n",
    "\n",
    "    return shopping_list.get_items()\n",
    "\n",
    "\n",
    "# Mount the MCP SSE app at '/'\n",
    "\n",
    "app.mount('/', mcp.sse_app())\n",
    "\n",
    "Here’s what’s happening in this code:\n",
    "\n",
    "    First, we import the necessary modules, including FastAPI and our MCP server instance.\n",
    "\n",
    "    Next, we create a FastAPI app.\n",
    "\n",
    "    Then, we add a regular HTTP endpoint at /items/ that returns the current shopping list. This is just a typical web route in FastAPI — when someone visits /items/ in their browser or makes a request to that URL, they’ll get back the list of shopping items.\n",
    "\n",
    "    The key part is the line app.mount('/', mcp.sse_app()). Here, we mount our MCP server’s SSE (Server-Sent Events) app at the root path of the FastAPI application. This means any requests to the root (such as /sse) will be handled by our MCP server, while other routes (like /items/) are handled by FastAPI.\n",
    "\n",
    "The mcp.sse_app() method returns an ASGI-compatible application specifically designed to handle Server-Sent Events (SSE) for the MCP server. This application is not a FastAPI app but a standalone ASGI app built for streaming communication. By mounting it within the FastAPI application using app.mount('/', mcp.sse_app()), FastAPI transparently forwards requests to the MCP server’s SSE app, leveraging FastAPI’s ASGI-compliant structure. This integration allows you to combine the strengths of both frameworks: you can serve your MCP tools for real-time agent communication and also provide regular API endpoints, all within a single, unified application.\n",
    "Running the Combined Application with Uvicorn\n",
    "\n",
    "To run your combined FastAPI and MCP server application, you use Uvicorn, which is an ASGI server designed for high performance. In your code, you see the following block:\n",
    "\n",
    "Python\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    uvicorn.run(\n",
    "\n",
    "        \"main:app\",\n",
    "\n",
    "        host=\"0.0.0.0\",\n",
    "\n",
    "        port=3000,\n",
    "\n",
    "        reload=True\n",
    "\n",
    "    )\n",
    "\n",
    "This tells Python to start the Uvicorn server, serving your FastAPI app on port 3000. The reload=True option is helpful during development, as it automatically restarts the server when you make changes to your code.\n",
    "\n",
    "To start the server, you can simply run the following command from the directory containing your script:\n",
    "\n",
    "Bash\n",
    "\n",
    "python your_script.py\n",
    "\n",
    "Once the server is running, you can access your regular API endpoints and your MCP server tools from the same application.\n",
    "Agent Integration Example\n",
    "\n",
    "Now, let’s see how an agent can connect to your MCP server running inside the FastAPI app. Here is an example agent script:\n",
    "\n",
    "Python\n",
    "\n",
    "import asyncio\n",
    "\n",
    "from agents import Agent, Runner\n",
    "\n",
    "from agents.mcp import MCPServerSse\n",
    "\n",
    "\n",
    "async def main():\n",
    "\n",
    "    # Setup the SSE server parameters\n",
    "\n",
    "    server_params = {\"url\": \"http://localhost:3000/sse\"}\n",
    "\n",
    "\n",
    "    # Connect to the MCP server over SSE\n",
    "\n",
    "    async with MCPServerSse(params=server_params) as mcp_server:\n",
    "\n",
    "        # Create an agent\n",
    "\n",
    "        agent = Agent(\n",
    "\n",
    "            name=\"OpenAI Shopping Agent\",\n",
    "\n",
    "            instructions=\"You are an assistant that uses shopping list tools to assist with a shopping list\",\n",
    "\n",
    "            mcp_servers=[mcp_server],\n",
    "\n",
    "            model=\"gpt-4.1\"\n",
    "\n",
    "        )\n",
    "\n",
    "        \n",
    "\n",
    "        # Run the agent\n",
    "\n",
    "        result = await Runner.run(\n",
    "\n",
    "            starting_agent=agent,\n",
    "\n",
    "            input=\"Give me my shopping list\"\n",
    "\n",
    "        )\n",
    "\n",
    "\n",
    "        # Print the final output\n",
    "\n",
    "        print(result.final_output)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    asyncio.run(main())\n",
    "\n",
    "In this script, the client connects to your MCP server by establishing a real-time SSE (Server-Sent Events) connection to the endpoint you set up in your FastAPI app (for example, http://localhost:3000/sse). The MCPServerSse class manages this connection, allowing the agent and server to exchange messages directly.\n",
    "\n",
    "Once the connection is established, the agent is given instructions to use the shopping list tools and processes the sample input. When the agent needs to use a tool (like getting the shopping list), it sends a request to the /messages endpoint on your server. FastAPI routes this request to the MCP server, which processes it and sends the response back to the agent over the SSE connection. This setup allows the agent to interact with your custom tools in real time and return the final result.\n",
    "Mounting the MCP Server at a Custom Route\n",
    "\n",
    "You have the flexibility to mount your MCP server at any route within your FastAPI application—not just at the root ('/'). This is an important architectural decision that can help you keep your application organized, avoid route conflicts, and apply different access controls as your project grows.\n",
    "\n",
    "For example, mounting your MCP server at /mcp is a common choice to clearly separate MCP-related endpoints from your main API:\n",
    "\n",
    "Python\n",
    "\n",
    "# Mount the MCP SSE app at '/mcp'\n",
    "\n",
    "app.mount('/mcp', mcp.sse_app())\n",
    "\n",
    "With this configuration, all requests to /mcp and its subpaths (like /mcp/sse) are handled by your MCP server, while your other FastAPI endpoints (such as /items/) remain unaffected and accessible as usual.\n",
    "\n",
    "Why is choosing a custom route important?\n",
    "\n",
    "    Clear separation of concerns: By mounting at a dedicated path like /mcp, you keep your MCP endpoints distinct from your main API, making your application easier to maintain and reason about.\n",
    "    Scalability and flexibility: As your application grows, this separation helps prevent route conflicts and allows you to expand your API surface without worrying about overlapping paths.\n",
    "    Security and access control: You can apply specific authentication or authorization rules to the /mcp path, giving you fine-grained control over who can access your agent tools.\n",
    "\n",
    "If you decide to mount your MCP server at a custom route, remember to update your client's connection URL accordingly:\n",
    "\n",
    "Python\n",
    "\n",
    "server_params = {\"url\": \"http://localhost:3000/mcp/sse\"}\n",
    "\n",
    "This ensures the client connects to the correct endpoint for the MCP server. The handshake at /mcp/sse establishes a real-time connection, allowing the server to send events and instructions back to the agent. After the handshake, when the agent needs to use a tool, the client sends requests to the /mcp/messages endpoint as directed by the server. The MCP server processes these requests—such as adding an item to a shopping list or retrieving data—and sends the results back through the established SSE connection. This separation of endpoints keeps communication organized and efficient, and by mounting your MCP server at /mcp, your application structure remains clean and scalable for more complex scenarios.\n",
    "Summary & Preparing for Practice\n",
    "\n",
    "In this lesson, you learned how to mount your MCP server inside a FastAPI application, allowing you to serve both MCP tools and regular API endpoints from a single, scalable ASGI app. You saw how to use FastAPI’s app.mount() method to integrate your MCP server and how to run the combined application using Uvicorn. You also reviewed how an agent can connect to your MCP server through the mounted endpoint and complete real-world tasks.\n",
    "\n",
    "This approach makes your applications more flexible and production-ready, as you can now combine agent tools and standard web APIs in one place. You are now ready to practice these skills in hands-on exercises. Great work progressing through this advanced integration technique!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d314189b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install fastapi uvicorn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c326dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uvicorn\n",
    "from fastapi import FastAPI\n",
    "from shopping_list import ShoppingListService\n",
    "from mcp_server import mcp  # Import the MCP server with the shopping list tools\n",
    "\n",
    "# Create the FastAPI app\n",
    "app = FastAPI()\n",
    "\n",
    "# Create a shopping list service instance\n",
    "shopping_list = ShoppingListService()\n",
    "\n",
    "# Regular FastAPI route for getting all shopping list items\n",
    "@app.get(\"/items/\")\n",
    "async def get_all_items():\n",
    "    \"\"\"Get all shopping list items.\"\"\"\n",
    "    return shopping_list.get_items()\n",
    "\n",
    "# Mount the MCP SSE app at '/'\n",
    "app.mount('/', mcp.sse_app())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938fbdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    uvicorn.run(\n",
    "        \"main:app\",\n",
    "        host=\"0.0.0.0\",\n",
    "        port=3000,\n",
    "        reload=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd780c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "python your_script.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a361c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from agents import Agent, Runner\n",
    "from agents.mcp import MCPServerSse\n",
    "\n",
    "async def main():\n",
    "    # Setup the SSE server parameters\n",
    "    server_params = {\"url\": \"http://localhost:3000/sse\"}\n",
    "\n",
    "    # Connect to the MCP server over SSE\n",
    "    async with MCPServerSse(params=server_params) as mcp_server:\n",
    "        # Create an agent\n",
    "        agent = Agent(\n",
    "            name=\"OpenAI Shopping Agent\",\n",
    "            instructions=\"You are an assistant that uses shopping list tools to assist with a shopping list\",\n",
    "            mcp_servers=[mcp_server],\n",
    "            model=\"gpt-4.1\"\n",
    "        )\n",
    "        \n",
    "        # Run the agent\n",
    "        result = await Runner.run(\n",
    "            starting_agent=agent,\n",
    "            input=\"Give me my shopping list\"\n",
    "        )\n",
    "\n",
    "        # Print the final output\n",
    "        print(result.final_output)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df374b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount the MCP SSE app at '/mcp'\n",
    "app.mount('/mcp', mcp.sse_app())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8105f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "server_params = {\"url\": \"http://localhost:3000/mcp/sse\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0466db7",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "You just learned how FastAPI and ASGI work together to build modern Python web applications. Now, let’s make sure you can run a basic FastAPI app on your own.\n",
    "\n",
    "In this task, you'll start the provided FastAPI shopping list application and confirm that it works as expected. No code changes are needed for this step.\n",
    "\n",
    "Follow these steps:\n",
    "\n",
    "    Open your terminal.\n",
    "    Navigate to the app directory.\n",
    "    Run the FastAPI application using the command:\n",
    "    python main.py\n",
    "    Watch the terminal for a message indicating that the server is running on port 3000.\n",
    "\n",
    "This will help you become comfortable with running FastAPI apps before you move on to integrating the MCP server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cef5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uvicorn\n",
    "from fastapi import FastAPI\n",
    "from shopping_list import ShoppingListService\n",
    "\n",
    "# Create the FastAPI app\n",
    "app = FastAPI()\n",
    "\n",
    "# Create a shopping list service instance\n",
    "shopping_list = ShoppingListService()\n",
    "\n",
    "# Regular FastAPI route for getting all shopping list items\n",
    "@app.get(\"/items/\")\n",
    "async def get_all_items():\n",
    "    \"\"\"Get all shopping list items.\"\"\"\n",
    "    return shopping_list.get_items()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the server\n",
    "    uvicorn.run(\n",
    "        \"main:app\",\n",
    "        host=\"0.0.0.0\",\n",
    "        port=3000,\n",
    "        reload=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30542d2b",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "Now, let’s take the next step and connect your MCP server to the FastAPI application so that both regular endpoints and agent tools are available together within a single ASGI application.\n",
    "\n",
    "Your task is to integrate the MCP server into the FastAPI app by:\n",
    "\n",
    "    Importing the mcp_server module into the main application file.\n",
    "    Mounting the MCP server’s SSE app at the '/' path using FastAPI’s app.mount() method.\n",
    "\n",
    "There’s no need to manually start the FastAPI app—it’s already running in debug mode for you. The agent code is also preconfigured with the correct URL to connect to your MCP server. Once you’ve made your changes, simply click the Run button. The agent will automatically connect to your mounted MCP server (just like it would to any SSE server) and should be able to use the tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e33e1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uvicorn\n",
    "from fastapi import FastAPI\n",
    "from shopping_list import ShoppingListService\n",
    "# TODO: Import the MCP server module\n",
    "from agents.mcp import MCPServerSse\n",
    "from mcp_server import mcp\n",
    "\n",
    "# Create the FastAPI app\n",
    "app = FastAPI()\n",
    "\n",
    "# Create a shopping list service instance\n",
    "shopping_list = ShoppingListService()\n",
    "\n",
    "\n",
    "# Regular FastAPI route for getting all shopping list items\n",
    "@app.get(\"/items/\")\n",
    "async def get_all_items():\n",
    "    \"\"\"Get all shopping list items.\"\"\"\n",
    "    return shopping_list.get_items()\n",
    "\n",
    "# TODO: Mount the MCP SSE app at the root path\n",
    "app.mount('/', mcp.sse_app())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the server\n",
    "    uvicorn.run(\n",
    "        \"main:app\",\n",
    "        host=\"0.0.0.0\",\n",
    "        port=3000,\n",
    "        reload=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe2c1e7",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "In this task, the MCP server is all set and mounted inside a FastAPI app, so both your shopping list tools and regular API endpoints are ready to go.\n",
    "\n",
    "However, when we try running the agent script, the handshake with the MCP server doesn’t go through as expected. Take a close look at the provided code, spot what’s off in the agent’s configuration, and fix it so the agent can connect, communicate, and use the shopping list tools just like it should."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5feec3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent.py\n",
    "import asyncio\n",
    "from agents import Agent, Runner\n",
    "from agents.mcp import MCPServerSse\n",
    "\n",
    "\n",
    "async def main():\n",
    "    # Setup the SSE server parameters\n",
    "    server_params = {\"url\": \"http://localhost:3000/sse\"} # adjusted url to include /sse at end\n",
    "\n",
    "    # Connect to the MCP server over SSE\n",
    "    async with MCPServerSse(params=server_params) as mcp_server:\n",
    "        # Create an agent\n",
    "        agent = Agent(\n",
    "            name=\"OpenAI Shopping Agent\",\n",
    "            instructions=\"You are an assistant that uses shopping list tools to assist with a shopping list\",\n",
    "            mcp_servers=[mcp_server],\n",
    "            model=\"gpt-4.1\"\n",
    "        )\n",
    "        \n",
    "        # Run the agent\n",
    "        result = await Runner.run(\n",
    "            starting_agent=agent,\n",
    "            input=\"Give me my shopping list\"\n",
    "        )\n",
    "\n",
    "        # Print the final output\n",
    "        print(result.final_output)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42060cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main.py\n",
    "import uvicorn\n",
    "from fastapi import FastAPI\n",
    "from shopping_list import ShoppingListService\n",
    "from mcp_server import mcp  # Import the MCP server with tools\n",
    "\n",
    "# Create the FastAPI app\n",
    "app = FastAPI()\n",
    "\n",
    "# Create a shopping list service instance\n",
    "shopping_list = ShoppingListService()\n",
    "\n",
    "\n",
    "# Regular FastAPI route for getting all shopping list items\n",
    "@app.get(\"/items/\")\n",
    "async def get_all_items():\n",
    "    \"\"\"Get all shopping list items.\"\"\"\n",
    "    return shopping_list.get_items()\n",
    "\n",
    "# Mount the MCP SSE app at '/'\n",
    "app.mount('/', mcp.sse_app())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the server\n",
    "    uvicorn.run(\n",
    "        \"main:app\",\n",
    "        host=\"0.0.0.0\",\n",
    "        port=3000,\n",
    "        reload=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50eee660",
   "metadata": {},
   "source": [
    "# final exercise\n",
    "Imagine you're building a growing application that needs to serve both regular API endpoints and agent tools. As your app expands, you want to keep things organized by placing different services in their own dedicated paths.\n",
    "\n",
    "Your task is to:\n",
    "\n",
    "    Mount the MCP server's SSE app at the /mcp path instead of the root path in your FastAPI application.\n",
    "    Update the agent's connection URL so that it matches the new location of the MCP server (/mcp/sse).\n",
    "\n",
    "This customization will help you maintain a clean architecture as your application grows, allowing you to add more services alongside your agent tools without path conflicts. It's a common practice in production environments where multiple services need to coexist under the same domain.s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5dfcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent.py\n",
    "\n",
    "import asyncio\n",
    "from agents import Agent, Runner\n",
    "from agents.mcp import MCPServerSse\n",
    "\n",
    "\n",
    "async def main():\n",
    "    # TODO: Update the server URL to match the new MCP server mount path\n",
    "    server_params = {\"url\": \"http://localhost:3000/mcp/sse\"}\n",
    "\n",
    "    # Connect to the MCP server over SSE\n",
    "    async with MCPServerSse(params=server_params) as mcp_server:\n",
    "        # Create an agent\n",
    "        agent = Agent(\n",
    "            name=\"OpenAI Shopping Agent\",\n",
    "            instructions=\"You are an assistant that uses shopping list tools to assist with a shopping list\",\n",
    "            mcp_servers=[mcp_server],\n",
    "            model=\"gpt-4.1\"\n",
    "        )\n",
    "        \n",
    "        # Run the agent\n",
    "        result = await Runner.run(\n",
    "            starting_agent=agent,\n",
    "            input=\"Give me my shopping list\"\n",
    "        )\n",
    "\n",
    "        # Print the final output\n",
    "        print(result.final_output)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cd525e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main.py\n",
    "\n",
    "import uvicorn\n",
    "from fastapi import FastAPI\n",
    "from shopping_list import ShoppingListService\n",
    "from mcp_server import mcp\n",
    "\n",
    "# Create the FastAPI app\n",
    "app = FastAPI()\n",
    "\n",
    "# Create a shopping list service instance\n",
    "shopping_list = ShoppingListService()\n",
    "\n",
    "\n",
    "# Regular FastAPI route for getting all shopping list items\n",
    "@app.get(\"/items/\")\n",
    "async def get_all_items():\n",
    "    \"\"\"Get all shopping list items.\"\"\"\n",
    "    return shopping_list.get_items()\n",
    "\n",
    "# TODO: Mount the MCP SSE app at '/mcp' instead of the root path\n",
    "app.mount('/mcp', mcp.sse_app())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the server\n",
    "    uvicorn.run(\n",
    "        \"main:app\",\n",
    "        host=\"0.0.0.0\",\n",
    "        port=3000,\n",
    "        reload=True\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
