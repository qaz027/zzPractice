{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c5e9501",
   "metadata": {},
   "source": [
    "# Data Cleaning and Preprocessing in Machine Learning\n",
    "\n",
    "# Topic Overview\n",
    "Welcome! Today, we embark on an exploration journey into the role of data preprocessing in the machine learning landscape. And there's no better way to learn than by tackling real-world data. Thus, we'll be utilizing the Titanic dataset, a rich dataset detailing the passenger manifest from the ill-fated maiden voyage of this once-lauded \"unsinkable\" ship.\n",
    "\n",
    "Data preprocessing is a vital preliminary step in any machine learning pipeline, capable of transforming raw, discordant data into a format that can be effectively utilized by machine learning algorithms. This whole process includes diverse techniques such as cleaning the data, dealing with missing values, data format transformations, and data normalization. In this lesson, we set the scene for their application.\n",
    "\n",
    "By the conclusion of today's lesson, you'll possess an understanding of the necessity of preprocessing in machine learning, an overview of the structure and complexity of the Titanic dataset, and the ability to apply preliminary data analysis techniques to extract initial insights.\n",
    "\n",
    "So, fasten your seatbelts and start the engines!\n",
    "\n",
    "# Introduction to Data Preprocessing\n",
    "Data preprocessing is the heart of any machine learning pipeline, capable of magnifying accuracy when done right or leading to poor performance when overlooked. The quality of the output of any machine learning model is directly proportional to the quality of input data. Hence the Golden Rule, \"Garbage In, Garbage Out.\"\n",
    "\n",
    "In simple terms, the goal of data preprocessing is to cleanse, transform, and format the raw data into a structure that makes it ready for machine learning algorithms. Choosing the right techniques under preprocessing often depends on the specifics of your data, as such, there is no \"one-size-fits-all\" strategy.\n",
    "\n",
    "The section today works like an introduction to this broad ocean of skills and sets the foundation for how you'll approach datasets in ensuing lessons.\n",
    "\n",
    "# Overview of the Titanic Dataset\n",
    "Having understood the concept of preprocessing, it's time to roll up our sleeves and get our hands dirty with the Titanic dataset. We aim to understand the data structure and its characteristics.\n",
    "\n",
    "The Titanic dataset comes pre-packaged in the Seaborn library, a visualization library in Python. Let's go ahead and load the dataset.\n",
    "\n",
    "```python\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Load Titanic dataset\n",
    "titanic_data = sns.load_dataset('titanic')\n",
    "\n",
    "# Display the first few records\n",
    "print(titanic_data.head())\n",
    "\n",
    "# Review the structure of the dataset\n",
    "print(titanic_data.info())\n",
    "```\n",
    "\n",
    "```md\n",
    "   survived  pclass     sex   age  ...  deck  embark_town  alive  alone\n",
    "0         0       3    male  22.0  ...   NaN  Southampton     no  False\n",
    "1         1       1  female  38.0  ...     C    Cherbourg    yes  False\n",
    "2         1       3  female  26.0  ...   NaN  Southampton    yes   True\n",
    "3         1       1  female  35.0  ...     C  Southampton    yes  False\n",
    "4         0       3    male  35.0  ...   NaN  Southampton     no   True\n",
    "\n",
    "[5 rows x 15 columns]\n",
    "\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 891 entries, 0 to 890\n",
    "Data columns (total 15 columns):\n",
    " #   Column       Non-Null Count  Dtype   \n",
    "---  ------       --------------  -----   \n",
    " 0   survived     891 non-null    int64   \n",
    " 1   pclass       891 non-null    int64   \n",
    " 2   sex          891 non-null    object  \n",
    " 3   age          714 non-null    float64 \n",
    " 4   sibsp        891 non-null    int64   \n",
    " 5   parch        891 non-null    int64   \n",
    " 6   fare         891 non-null    float64 \n",
    " 7   embarked     889 non-null    object  \n",
    " 8   class        891 non-null    category\n",
    " 9   who          891 non-null    object  \n",
    " 10  adult_male   891 non-null    bool    \n",
    " 11  deck         203 non-null    category\n",
    " 12  embark_town  889 non-null    object  \n",
    " 13  alive        891 non-null    object  \n",
    " 14  alone        891 non-null    bool    \n",
    "dtypes: bool(2), category(2), float64(2), int64(4), object(5)\n",
    "memory usage: 80.6+ KB\n",
    "None\n",
    "```\n",
    "In the script above, we imported the seaborn and pandas libraries to load the Titanic dataset and describe the data frame, respectively. The structure of the DataFrame is easily reviewed with the .info() method, dishing out crucial details like the number of non-null entries for each feature, the data type of each column, and the count of data points in each feature.\n",
    "\n",
    "# Drawing Insights from the Titanic Dataset\n",
    "Before parting, let's take a look at some general statistics from the Titanic dataset, which will help us gain a better understanding of what we just loaded.\n",
    "\n",
    "Pandas DataFrames provide us with the neat .describe() function, which returns various descriptive statistics that summarize the central tendency, dispersion, and shape of a dataset's distribution.\n",
    "\n",
    "```python\n",
    "print(titanic_data.describe())\n",
    "```\n",
    "\n",
    "```md\n",
    "         survived      pclass         age       sibsp       parch        fare\n",
    "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
    "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
    "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
    "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
    "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
    "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
    "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
    "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200\n",
    "```\n",
    "\n",
    "Using the .describe() function, you can see detailed statistics for each numeric column in your DataFrame. These include the number of non-missing values, mean, standard deviation, median (50 percentile), minimum, and maximum. Studying these statistics provides a fundamental understanding of the characteristics of the data you are working with.\n",
    "\n",
    "Keep in mind that all the impressive and advanced visualizations and models you'll hear about in data science and machine learning are often built on these humble statistics you're looking at. So, understand these well!\n",
    "\n",
    "# Lesson Summary and Practice\n",
    "Great job on reaching the end of the lesson! We started our journey by dipping our toes in the ocean of data preprocessing and explored the Titanic as an example dataset. We unfolded the mystery behind the data structure through some initial data analysis.\n",
    "\n",
    "Looking back, we started off with the significance of data preprocessing, moved to the initial exploration of the Titanic dataset through understanding its structure, and ended with drawing initial descriptive statistics of the dataset.\n",
    "\n",
    "For the next stage, get ready for some hands-on exploration of the Titanic dataset using Python and Pandas. The practice will involve gaining on-the-field experience in comprehending datasets. Remember, the magic often lies in the details, and the power to unravel that lies within practice. Keep going, and let the world of data keep fascinating you!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6f1873",
   "metadata": {},
   "source": [
    "Let's delve deeper! In the Titanic dataset, you have examined its basic structure and overall statistics. For targeted insights, adjust the code to display summary statistics specifically for the age and fare columns, offering a more focused view of this historical data. Are you ready to enhance your data preprocessing skills?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27f532e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   survived     891 non-null    int64   \n",
      " 1   pclass       891 non-null    int64   \n",
      " 2   sex          891 non-null    object  \n",
      " 3   age          714 non-null    float64 \n",
      " 4   sibsp        891 non-null    int64   \n",
      " 5   parch        891 non-null    int64   \n",
      " 6   fare         891 non-null    float64 \n",
      " 7   embarked     889 non-null    object  \n",
      " 8   class        891 non-null    category\n",
      " 9   who          891 non-null    object  \n",
      " 10  adult_male   891 non-null    bool    \n",
      " 11  deck         203 non-null    category\n",
      " 12  embark_town  889 non-null    object  \n",
      " 13  alive        891 non-null    object  \n",
      " 14  alone        891 non-null    bool    \n",
      "dtypes: bool(2), category(2), float64(2), int64(4), object(5)\n",
      "memory usage: 80.7+ KB\n",
      "None\n",
      "              age        fare\n",
      "count  714.000000  891.000000\n",
      "mean    29.699118   32.204208\n",
      "std     14.526497   49.693429\n",
      "min      0.420000    0.000000\n",
      "25%     20.125000    7.910400\n",
      "50%     28.000000   14.454200\n",
      "75%     38.000000   31.000000\n",
      "max     80.000000  512.329200\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "titanic_data = sns.load_dataset('titanic')\n",
    "\n",
    "# Display the structure of the dataset\n",
    "print(titanic_data.info())\n",
    "\n",
    "# Display summary statistics of the dataset\n",
    "print(titanic_data[['age','fare']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7077b6cc",
   "metadata": {},
   "source": [
    "Brilliant work so far, Space Voyager! We have a dataset ready for inspection, but it seems our script is tripping over its own feet. Can you identify the hiccup and get the dataset exploration back on track?\n",
    "\n",
    "The code should output the first few records, the dataset's info, and its general statistics. Look closely—the devil is in the details!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c531502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
      "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
      "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
      "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
      "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
      "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
      "\n",
      "     who  adult_male deck  embark_town alive  alone  \n",
      "0    man        True  NaN  Southampton    no  False  \n",
      "1  woman       False    C    Cherbourg   yes  False  \n",
      "2  woman       False  NaN  Southampton   yes   True  \n",
      "3  woman       False    C  Southampton   yes  False  \n",
      "4    man        True  NaN  Southampton    no   True  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   survived     891 non-null    int64   \n",
      " 1   pclass       891 non-null    int64   \n",
      " 2   sex          891 non-null    object  \n",
      " 3   age          714 non-null    float64 \n",
      " 4   sibsp        891 non-null    int64   \n",
      " 5   parch        891 non-null    int64   \n",
      " 6   fare         891 non-null    float64 \n",
      " 7   embarked     889 non-null    object  \n",
      " 8   class        891 non-null    category\n",
      " 9   who          891 non-null    object  \n",
      " 10  adult_male   891 non-null    bool    \n",
      " 11  deck         203 non-null    category\n",
      " 12  embark_town  889 non-null    object  \n",
      " 13  alive        891 non-null    object  \n",
      " 14  alone        891 non-null    bool    \n",
      "dtypes: bool(2), category(2), float64(2), int64(4), object(5)\n",
      "memory usage: 80.7+ KB\n",
      "None\n",
      "         survived      pclass         age       sibsp       parch        fare\n",
      "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
      "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
      "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
      "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
      "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
      "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
      "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
      "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Load Titanic dataset\n",
    "titanic_data = sns.load_dataset('titanic') \n",
    "\n",
    "# Display the first few records\n",
    "print(titanic_data.head())\n",
    "\n",
    "# Review the structure of the dataset\n",
    "print(titanic_data.info())\n",
    "\n",
    "# Print general statistics of the dataset\n",
    "print(titanic_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f532a4bc",
   "metadata": {},
   "source": [
    "# Wrangling Missing Data: Techniques Applied to the Titanic Dataset\n",
    "## Lesson Introduction\n",
    "Welcome to an intriguing lesson on missing data handling! Today, we're diving into the Titanic dataset, a passage in time to the early 20th century. Our main aim? To wrangle missing data using Python and Pandas. Don't worry if you're unfamiliar with these terms yet, we'll break them down one by one!\n",
    "\n",
    "Python: A high-level, interpreted programming language that is easy to learn yet powerful. It has bundles of libraries, like Pandas, that make data manipulation a breeze.\n",
    "Pandas: A Python library providing high-performance, easy-to-use data structures and data analysis tools.\n",
    "By the end of this lesson, you'll understand the basics of handling missing data, which is an essential step in preparing your data for machine learning models. So let's get started!\n",
    "\n",
    "## Understanding Missing Data\n",
    "As an analyst or data scientist, it's pivotal to understand why data might be missing, as it helps in choosing the best strategy to handle it. Missing data, which are like missing puzzle pieces, can occur due to several reasons, such as not being collected, being recorded incorrectly, or even being lost over time.\n",
    "\n",
    "Furthermore, missing data can be categorised as:\n",
    "\n",
    "Missing completely at random (MCAR): The missing data entries are random and don't correlate with any other data.\n",
    "Missing at random (MAR): The missing values depend on the values of other variables.\n",
    "Missing not at random (MNAR): The missing values have a particular pattern or logic.\n",
    "Identifying Missing Values in the Titanic Dataset\n",
    "Before we can consider how to handle missing data, let's learn how to identify it. We'll use the isnull() and sum() functions from the Pandas library to find the number of missing values in our Titanic dataset:\n",
    "\n",
    "```python\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Import Titanic dataset\n",
    "titanic_df = sns.load_dataset('titanic')\n",
    "\n",
    "# Identify missing values\n",
    "missing_values = titanic_df.isnull().sum()\n",
    "print(missing_values)\n",
    "The output from this code will be:\n",
    "```\n",
    "\n",
    "```Markdown\n",
    "Copy to clipboard\n",
    "survived         0\n",
    "pclass           0\n",
    "sex              0\n",
    "age            177\n",
    "sibsp            0\n",
    "parch            0\n",
    "fare             0\n",
    "embarked         2\n",
    "class            0\n",
    "who              0\n",
    "adult_male       0\n",
    "deck           688\n",
    "embark_town      2\n",
    "alive            0\n",
    "alone            0\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "In the output, you'll see each column name accompanied by a number that denotes the number of missing values in that column.\n",
    "\n",
    "## Strategies to Handle Missing Data\n",
    "Armed with the knowledge of missing data and its types, it's time to decide how to handle them. Broadly, you can consider three main strategies:\n",
    "\n",
    "Deletion: This involves removing the rows and columns containing missing data. However, this might lead to the loss of valuable information.\n",
    "Imputation: This includes filling missing values with substituted ones, like the mean, median, or mode (the most common value in the data frame).\n",
    "Prediction: This involves using a predictive model to estimate the missing values.\n",
    "A balance of intuition, experience, and technical know-how usually dictates the best method to use.\n",
    "\n",
    "## Handling Missing Data in the Titanic Dataset\n",
    "Let's get our hands dirty and handle missing data firsthand in the Titanic dataset. For the “age” feature, we'll fill in missing entries with the median passenger age. And, for the “deck” feature, where most entries are missing, we'll delete the entire column.\n",
    "\n",
    "```python\n",
    "# Dealing with missing values \n",
    "\n",
    "# Dropping columns with excessive missing data\n",
    "new_titanic_df = titanic_df.drop(columns=['deck'])\n",
    "\n",
    "# Imputing median age for missing age data\n",
    "new_titanic_df['age'].fillna(new_titanic_df['age'].median(), inplace=True)\n",
    "\n",
    "# Display the number of missing values post-imputation\n",
    "missing_values_updated = new_titanic_df.isnull().sum()\n",
    "print(missing_values_updated)\n",
    "The updated missing values count comes out to be:\n",
    "```\n",
    "\n",
    "\n",
    "```Markdown\n",
    "Copy to clipboard\n",
    "survived       0\n",
    "pclass         0\n",
    "sex            0\n",
    "age            0\n",
    "sibsp          0\n",
    "parch          0\n",
    "fare           0\n",
    "embarked       2\n",
    "class          0\n",
    "who            0\n",
    "adult_male     0\n",
    "embark_town    2\n",
    "alive          0\n",
    "alone          0\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "As you can see from the updated missing values count, we have successfully handled the missing data! Note that we could also use the dropna() function to handle missing data by removing rows with missing values. However, we should be cautious, as this might remove a significant portion of our data. Here's how you can do it: titanic_df.dropna().\n",
    "\n",
    "## Lesson Summary and Practice\n",
    "Well done! You have now explored the basics of handling missing data, an essential pre-processing step for any machine-learning model. The skill of dealing with missing data is a key arrow in any data scientist's quiver, ensuring that your data is clean and ready for modeling.\n",
    "\n",
    "Get set for some upcoming practice sessions that will provide you with opportunities to apply and reinforce what you've learned today. Feel the thrill as we continue venturing deeper into the world of data processing! Nothing should be missing from your data now, so it's time to wield your new skills!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0016b7",
   "metadata": {},
   "source": [
    "In the given code, we have already cleaned our Titanic dataset by addressing its missing values. The deck column has been removed due to an excessive number of missing data points, and missing values in age, embarked, and embark_town have been imputed with median and mode values, respectively. Run the code to check if all missing values have been handled and to see the improved state of our dataset, now ready for further analysis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74480526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before handling:\n",
      " survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n",
      "Missing values after handling:\n",
      " survived       0\n",
      "pclass         0\n",
      "sex            0\n",
      "age            0\n",
      "sibsp          0\n",
      "parch          0\n",
      "fare           0\n",
      "embarked       0\n",
      "class          0\n",
      "who            0\n",
      "adult_male     0\n",
      "embark_town    0\n",
      "alive          0\n",
      "alone          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "titanic_df = sns.load_dataset('titanic')\n",
    "\n",
    "# Identify and display missing values\n",
    "missing_values = titanic_df.isnull().sum()\n",
    "print(\"Missing values before handling:\\n\", missing_values)\n",
    "\n",
    "# Handle missing data by dropping the 'deck' column and imputing 'age'\n",
    "titanic_df.drop(columns=['deck'], inplace=True)\n",
    "titanic_df['age'].fillna(titanic_df['age'].median(), inplace=True)\n",
    "\n",
    "# Impute the 'embarked' and 'embark_town' columns with the most common value\n",
    "most_common_embarked = titanic_df['embarked'].mode()[0]\n",
    "titanic_df['embarked'].fillna(most_common_embarked, inplace=True)\n",
    "most_common_embark_town = titanic_df['embark_town'].mode()[0]\n",
    "titanic_df['embark_town'].fillna(most_common_embark_town, inplace=True)\n",
    "\n",
    "# Verify that missing data has been handled\n",
    "missing_values_after = titanic_df.isnull().sum()\n",
    "print(\"Missing values after handling:\\n\", missing_values_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f2735b",
   "metadata": {},
   "source": [
    "Superb progress, Space Voyager!\n",
    "\n",
    "Let's enhance our data imputation skills. In the provided starter code, you'll find a line where missing values in the 'embarked' column are filled with a placeholder. Your task is to modify this line to impute missing values with the most common 'embarked' category instead.\n",
    "\n",
    "Cosmo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a44655a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in age and embarked columns:\n",
      " age         177\n",
      "embarked      2\n",
      "dtype: int64\n",
      "\n",
      "Dataset information post-imputation:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   survived     891 non-null    int64   \n",
      " 1   pclass       891 non-null    int64   \n",
      " 2   sex          891 non-null    object  \n",
      " 3   age          891 non-null    float64 \n",
      " 4   sibsp        891 non-null    int64   \n",
      " 5   parch        891 non-null    int64   \n",
      " 6   fare         891 non-null    float64 \n",
      " 7   embarked     891 non-null    object  \n",
      " 8   class        891 non-null    category\n",
      " 9   who          891 non-null    object  \n",
      " 10  adult_male   891 non-null    bool    \n",
      " 11  deck         203 non-null    category\n",
      " 12  embark_town  889 non-null    object  \n",
      " 13  alive        891 non-null    object  \n",
      " 14  alone        891 non-null    bool    \n",
      "dtypes: bool(2), category(2), float64(2), int64(4), object(5)\n",
      "memory usage: 80.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "titanic_df = sns.load_dataset('titanic')\n",
    "\n",
    "# Identify and print the number of missing values in the 'age' and 'embarked' columns\n",
    "missing_values_age_embarked = titanic_df[['age', 'embarked']].isnull().sum()\n",
    "print('Missing values in age and embarked columns:\\n', missing_values_age_embarked)\n",
    "\n",
    "# Impute the missing values in the 'age' column with the median age\n",
    "titanic_df['age'].fillna(titanic_df['age'].median(), inplace=True)\n",
    "\n",
    "# Impute the missing values in the 'embarked' column with a placeholder value 'U' for Unknown\n",
    "#titanic_df['embarked'].fillna('U', inplace=True)\n",
    "titanic_df['embarked'].fillna(titanic_df['embarked'].value_counts().index[0], inplace=True)\n",
    "\n",
    "# Print the dataset info to confirm that there are no more missing values in 'age' and 'embarked'\n",
    "print('\\nDataset information post-imputation:')\n",
    "print(titanic_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bead1b65",
   "metadata": {},
   "source": [
    "Good job navigating the sea of data, Space Voyager! Now, let's put your skills to the test. Fill in the blanks to impute the missing ages, and clean up the dataset by removing a column that's mostly empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236b9716",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "titanic = sns.load_dataset('titanic')\n",
    "\n",
    "# Find the number of missing values in each column\n",
    "missing_values_before = titanic.isnull().sum()\n",
    "print(\"Missing values before handling:\")\n",
    "print(missing_values_before)\n",
    "\n",
    "# TODO: Replace missing data in 'age' column with a central tendency measure of your choice\n",
    "titanic['age'].fillna(titanic['age'].mean(), inplace=True)\n",
    "\n",
    "# TODO: Remove a column with too many missing values to salvage\n",
    "titanic.drop(columns=['deck'], inplace=True)\n",
    "\n",
    "# Verify the handling by checking for missing values again\n",
    "missing_values_after = titanic.isnull().sum()\n",
    "print(\"\\nMissing values after handling:\")\n",
    "print(missing_values_after)\n",
    "\n",
    "# Optionally, show the info of the dataset to visualize the changes\n",
    "print(\"\\nDataset information after handling missing data:\")\n",
    "print(titanic.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04dee82",
   "metadata": {},
   "source": [
    "Great job handling the missing values, Space Explorer! However, the code you have isn't acting as expected. It's generating an error when trying to handle missing categories in the 'age' column. Can you spot the glitch and adjust the thrusters so we can ensure a smooth data preprocessing journey?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630a5bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "titanic_df = sns.load_dataset('titanic')\n",
    "\n",
    "# Drop the 'deck' column due to excessive missing values\n",
    "titanic_df_cleaned = titanic_df.drop(columns=['deck'])\n",
    "\n",
    "# Impute the missing 'age' values with the median age\n",
    "median_age = titanic_df_cleaned['age'].median()\n",
    "titanic_df_cleaned['age'].fillna(median_age, inplace=True)\n",
    "\n",
    "# Impute the missing 'embarked' values with the mode\n",
    "mode_embarked = titanic_df_cleaned['embarked'].mode()[0]\n",
    "titanic_df_cleaned['embarked'].fillna(mode_embarked, inplace=True)\n",
    "\n",
    "# Impute the missing 'embark_town' values with the mode\n",
    "mode_embark_town = titanic_df_cleaned['embark_town'].mode()[0]\n",
    "titanic_df_cleaned['embark_town'].fillna(mode_embark_town, inplace=True)\n",
    "\n",
    "# Check for remaining missing values\n",
    "missing_values_after = titanic_df_cleaned.isnull().sum()\n",
    "print(missing_values_after)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
