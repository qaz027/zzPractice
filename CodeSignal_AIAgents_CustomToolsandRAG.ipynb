{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3023eaf2",
   "metadata": {},
   "source": [
    "# Lesson Introduction\n",
    "\n",
    "Welcome! Today, we’ll see how to build a simple **AI agent** that answers questions using external knowledge. Even advanced AI models sometimes need to look up information — just as you might check your notes or Google before answering a tough question.\n",
    "\n",
    "**Retrieval-Augmented Generation (RAG)** helps AI agents find and use relevant information from a knowledge base for more accurate answers. By the end, you’ll know how to create a basic agent that uses RAG to answer user queries more effectively.\n",
    "\n",
    "## Loading and Preparing Knowledge Base\n",
    "\n",
    "First, the agent needs access to knowledge. Here, our knowledge base is a `JSON` file with study tips and resources.\n",
    "\n",
    "Here’s how to load it in `Python`:\n",
    "\n",
    "```python\n",
    "import os\n",
    "import json\n",
    "\n",
    "def load_data(file_name):\n",
    "    \"\"\"Load knowledge base from JSON file.\"\"\"\n",
    "    current_dir = os.path.dirname(__file__)\n",
    "    dataset_file = os.path.join(current_dir, \"data\", file_name)\n",
    "    with open(dataset_file, 'r') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "data = load_data(\"data.json\")\n",
    "print(data)  # [{'id': 1, 'content': \"Read Chapter 7 of 'Clean Code' — focus on writing small, single-purpose functions.\"}, {'id': 2, 'content': \"Experiment with React's useContext by creating a theme toggler component.\"}, {'id': 3, 'content': 'Review different types of SQL joins — especially LEFT and FULL OUTER joins.'}, {'id': 4, 'content': 'Watch lecture on consensus algorithms — try to summarize Paxos in your own words.'}, {'id': 5, 'content': 'Figure out the difference between React Query and Redux for async data handling.'}, {'id': 6, 'content': \"Draft blog post: '3 Things I Learned About Writing Better Functions.'\"}, {'id': 7, 'content': 'Ask Aram about good beginner-friendly open-source projects to contribute to.'}]\n",
    "```\n",
    "\n",
    "This code locates and opens `data.json`, loading its content as a list of dictionaries. Each dictionary is a document, for example:\n",
    "\n",
    "```python\n",
    "{\n",
    "    \"id\": 2,\n",
    "    \"content\": \"Experiment with React's useContext by creating a theme toggler component.\"\n",
    "}\n",
    "```\n",
    "\n",
    "This simple structure works well for small knowledge sets. Larger, real-world knowledge bases follow the same principle: load and access information for the agent.\n",
    "\n",
    "## Simple RAG Retrieval Logic\n",
    "\n",
    "With the knowledge base loaded, the next step is retrieval — finding the most relevant document for a user’s question. We use a basic method: word overlap. We count how many words from the user’s question appear in each document. The document with the most overlap is chosen.\n",
    "\n",
    "Here’s the code:\n",
    "\n",
    "```python\n",
    "def rag_retrieval(query, knowledge_base):\n",
    "    query_words = set(query.lower().split())\n",
    "    best_doc = None\n",
    "    best_overlap = 0\n",
    "    for doc in knowledge_base:\n",
    "        doc_words = set(doc[\"content\"].lower().split())\n",
    "        overlap = len(query_words & doc_words)\n",
    "        if overlap > best_overlap:\n",
    "            best_overlap = overlap\n",
    "            best_doc = doc\n",
    "    return best_doc if best_overlap > 0 else None\n",
    "\n",
    "# Example usage:\n",
    "query = \"How should I start tackling React useContext\"\n",
    "best_doc = rag_retrieval(query, data)\n",
    "print(best_doc)  # {'id': 2, 'content': \"Experiment with React's useContext by creating a theme toggler component.\"}\n",
    "```\n",
    "\n",
    "The query and each document are split into lowercase words, and the code counts overlapping words. The document with the highest overlap is returned. This method is simple and fast. More advanced systems use semantic search, but word overlap is a great way to start understanding retrieval.\n",
    "\n",
    "## Building the Agent Prompt\n",
    "\n",
    "After finding the most relevant document, we give this context to the agent. The agent uses both the user’s question and the retrieved document to answer. We build a prompt that combines both:\n",
    "\n",
    "```python\n",
    "def build_prompt(user_prompt, rag_document=None):\n",
    "    if rag_document:\n",
    "        return f\"Based on the following document: {rag_document['content']}, {user_prompt}\"\n",
    "    return user_prompt\n",
    "\n",
    "# Example usage:\n",
    "user_prompt = \"How should I start tackling React useContext\"\n",
    "prompt_with_context = build_prompt(user_prompt, best_doc)\n",
    "print(prompt_with_context)  # Based on the following document: Experiment with React's useContext by creating a theme toggler component., How should I start tackling React useContext\n",
    "```\n",
    "\n",
    "If a document is found, the prompt includes its content. If not, the agent just gets the original question. Providing context helps the agent focus on useful information, leading to better answers. This is the core of RAG: retrieval plus generation.\n",
    "\n",
    "## Running the Agent\n",
    "\n",
    "Now, let’s see how the agent uses the prompt to generate a response. The agent is defined with instructions and run using a helper:\n",
    "\n",
    "```python\n",
    "from agents import Agent, Runner\n",
    "\n",
    "AGENT = Agent(\n",
    "    name=\"Learning Assistant\",\n",
    "    instructions=(\n",
    "        \"You are a personal learning assistant. \"\n",
    "        \"Whenever asked a question about learning plans, use the context provided to answer questions.\"\n",
    "    )\n",
    ")\n",
    "\n",
    "def ask_agent(prompt):\n",
    "    try:\n",
    "        result = Runner.run_sync(AGENT, prompt)\n",
    "        return result.final_output\n",
    "    except Exception as e:\n",
    "        print(f\"Agent error: {e}\")\n",
    "        raise\n",
    "\n",
    "# Example usage:\n",
    "response = ask_agent(prompt_with_context)\n",
    "print(response)  # (Output will depend on the agent's implementation, e.g., \"To start with React's useContext, try building a simple theme toggler as described in the document.\")\n",
    "```\n",
    "\n",
    "The agent gets the prompt (with or without context), generates a response using its instructions and the context, and prints the response. This workflow — retrieval, prompt building, and response generation — is the foundation of a simple RAG agent.\n",
    "\n",
    "## Lesson Summary and Practice Introduction\n",
    "\n",
    "You’ve learned how to build a simple agent using **Retrieval-Augmented Generation (RAG)** for better answers. We covered loading a knowledge base from `JSON`, retrieving the most relevant document using word overlap, building a prompt with the user’s question and context, and running the agent to generate a response. This approach makes AI agents more helpful, especially for specific topics or documents.\n",
    "\n",
    "Now it’s your turn! Next, you’ll practice building and running your own RAG-powered agent. You’ll load data, retrieve relevant information, and generate answers using an agent. This hands-on work will reinforce your understanding and prepare you for more advanced RAG techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0e89c8",
   "metadata": {},
   "source": [
    "Great job on setting up the basic RAG retrieval! Now, let's enhance the retrieval function.\n",
    "\n",
    "Currently, it returns only the document with the highest word overlap. Modify it to return a list of all documents that share at least one word with the query, sorted by the number of overlapping words in descending order.\n",
    "\n",
    "This change will allow the agent to consider multiple relevant documents, thereby improving its response quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97c03ef7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'rag_agent'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrag_agent\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ask_agent\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01magents\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Runner\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_data\u001b[39m(file_name):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'rag_agent'"
     ]
    }
   ],
   "source": [
    "# exercise 1\n",
    "import os\n",
    "import json\n",
    "from rag_agent import ask_agent\n",
    "from agents import Runner\n",
    "\n",
    "def load_data(file_name):\n",
    "    \"\"\"Load sample knowledge base content from JSON file.\"\"\"\n",
    "    current_dir = os.path.dirname(__file__)\n",
    "    dataset_file = os.path.join(current_dir, \"data\", file_name)\n",
    "    with open(dataset_file, 'r') as file:\n",
    "        return json.load(file)\n",
    "        \n",
    "def rag_retrieval(query, knowledge_base):\n",
    "    query_words = set(query.lower().split())\n",
    "    best_doc_id = None\n",
    "    best_overlap = 0\n",
    "    any_match = []\n",
    "    for doc in knowledge_base:\n",
    "        doc_words = set(doc[\"content\"].lower().split())\n",
    "        overlap = len(query_words.intersection(doc_words))\n",
    "        if overlap > 0: #revised from best_overlap:\n",
    "            best_overlap = overlap\n",
    "            #best_doc = doc\n",
    "            any_match.append({\"document\":doc,\"overlap_count\":overlap})\n",
    "    any_match = sorted(any_match, key=lambda x: x[\"overlap_count\"], reverse=True)\n",
    "    return_docs = [x[\"document\"] for x in any_match]\n",
    "    return return_docs if best_overlap > 0 else None\n",
    "\n",
    "def build_prompt(user_prompt, rag_document_list=None):\n",
    "    if rag_document_list:\n",
    "        prompt_part1 = f\"Based on the following documents: \"\n",
    "        prompt_part2 = \"\"\n",
    "        for doc in rag_document_list:\n",
    "           prompt_part2 += doc['content'] \n",
    "        return prompt_part1 + prompt_part2 + f\"{user_prompt}\"#f\"Based on the following document: {rag_document['content']}, {user_prompt}\"\n",
    "    return user_prompt\n",
    "\n",
    "\n",
    "def main():\n",
    "    data = load_data(\"data.json\")\n",
    "\n",
    "    query = \"How should I start tackling React useContext\"\n",
    "\n",
    "    rag_document = rag_retrieval(query, data)\n",
    "\n",
    "    query = build_prompt(query, rag_document)\n",
    "\n",
    "    response = ask_agent(query)\n",
    "\n",
    "    print(response)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb047671",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "\n",
    "Nice work on returning multiple matching notes in the last step. Now, tighten retrieval and structure the prompt.\n",
    "\n",
    "Add a top_k parameter to limit results to the most relevant notes by word overlap.\n",
    "\n",
    "Then, list those notes as a bulleted Context in the prompt. If nothing matches, send the original question as is.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99611bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from rag_agent import ask_agent\n",
    "from agents import Runner\n",
    "\n",
    "def load_data(file_name):\n",
    "    \"\"\"Load sample knowledge base content from JSON file.\"\"\"\n",
    "    current_dir = os.path.dirname(__file__)\n",
    "    dataset_file = os.path.join(current_dir, \"data\", file_name)\n",
    "    with open(dataset_file, 'r') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "def rag_retrieval(query, knowledge_base, top_k=10):\n",
    "    \"\"\"\n",
    "    Return up to top_k most relevant documents by word overlap.\n",
    "    \"\"\"\n",
    "    # TODO: Convert the query to lowercase words and store in a set\n",
    "    query_words = set(query.lower().split())\n",
    "\n",
    "    # Collect (doc, overlap_score) for docs with at least one overlapping word\n",
    "    scored = []\n",
    "\n",
    "    # TODO: Iterate through the knowledge base and compute overlap\n",
    "    for doc in knowledge_base:\n",
    "        # TODO: Lowercase and split document content into words\n",
    "        doc_words = set(doc[\"content\"].lower().split())\n",
    "\n",
    "        # TODO: Compute overlap score between query_words and doc_words\n",
    "        overlap = len(query_words.intersection(doc_words))\n",
    "\n",
    "        # TODO: Keep only documents with positive overlap\n",
    "        if overlap > 0:\n",
    "            scored.append((doc, overlap))\n",
    "\n",
    "    # TODO: Sort by overlap descending\n",
    "    scored.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # TODO: Return only the top_k documents (no scores)\n",
    "    return [d for d, _ in scored[:top_k]]\n",
    "\n",
    "def build_prompt(user_prompt, rag_documents=None):\n",
    "    \"\"\"\n",
    "    Build a prompt that lists retrieved notes under a Context section.\n",
    "    If no documents are provided, return the original question.\n",
    "    \"\"\"\n",
    "    if rag_documents:\n",
    "        # TODO: Create a bullet list string from rag_documents' content lines\n",
    "        context_lines = \"\\n\".join(f\"- {doc['content']}\" for doc in rag_documents)\n",
    "        # TODO: Compose the final prompt with question, context, and answer cue\n",
    "        return f\"Question: {user_prompt}\\nContext:\\n{context_lines}\\nAnswer:\"\n",
    "    return user_prompt\n",
    "\n",
    "def main():\n",
    "    data = load_data(\"data.json\")\n",
    "\n",
    "    query = \"How should I start tackling React useContext\"\n",
    "    top_k = 5\n",
    "\n",
    "    rag_documents = rag_retrieval(query, data, top_k=top_k)\n",
    "\n",
    "    prompt = build_prompt(query, rag_documents)\n",
    "\n",
    "    response = ask_agent(prompt)\n",
    "\n",
    "    print(response)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cc0726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercise 3\n",
    "# TODO: Import needed modules:\n",
    "# - os and json for reading the JSON file\n",
    "# - re for simple punctuation removal\n",
    "# - ask_agent from rag_agent to run the agent with a prompt\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Implement load_data(file_name):\n",
    "# - Build the path to data/<file_name> using os.path\n",
    "# - Open and load JSON content\n",
    "# - Return the loaded list of note dicts\n",
    "\n",
    "# TODO: Implement tokenize(text):\n",
    "# - Lowercase the text\n",
    "# - Remove punctuation using a regex (replace non-word, non-space with a space)\n",
    "# - Split into words and return a set of unique tokens\n",
    "\n",
    "# TODO: Implement rag_retrieval(query, knowledge_base):\n",
    "# - Tokenize the query\n",
    "# - For each document in the knowledge base:\n",
    "#   - Tokenize doc[\"content\"]\n",
    "#   - Compute overlap size between query tokens and doc tokens\n",
    "# - Track the best document by highest overlap score\n",
    "# - Tie-break: if scores are equal and positive, choose the doc with smaller id\n",
    "# - Return the best document, or None if there is no overlap\n",
    "\n",
    "# TODO: Implement build_prompt(user_prompt, rag_document=None):\n",
    "# - If rag_document is provided, return:\n",
    "#   \"Question: <user_prompt>\\nContext: <rag_document['content']>\\nAnswer:\"\n",
    "# - Otherwise, return the original user_prompt\n",
    "\n",
    "# TODO: Implement main():\n",
    "# - Load data from \"data.json\"\n",
    "# - Define a user query like: \"What should I focus on for SQL joins?\"\n",
    "# - Run rag_retrieval to get the best document\n",
    "# - Build the prompt with build_prompt\n",
    "# - Call ask_agent(prompt) and print the response\n",
    "\n",
    "# TODO: Add the standard Python entry point guard to call main():\n",
    "# if __name__ == '__main__':\n",
    "#     main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc120085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution exercise 3\n",
    "# TODO: Import needed modules:\n",
    "# - os and json for reading the JSON file\n",
    "# - re for simple punctuation removal\n",
    "# - ask_agent from rag_agent to run the agent with a prompt\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from rag_agent import ask_agent\n",
    "from agents import Runner\n",
    "\n",
    "\n",
    "# TODO: Implement load_data(file_name):\n",
    "# - Build the path to data/<file_name> using os.path\n",
    "# - Open and load JSON content\n",
    "# - Return the loaded list of note dicts\n",
    "def load_data(file_name):\n",
    "    \"\"\"Load sample knowledge base content from JSON file.\"\"\"\n",
    "    current_dir = os.path.dirname(__file__)\n",
    "    dataset_file = os.path.join(current_dir, \"data\", file_name)\n",
    "    with open(dataset_file, 'r') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "\n",
    "# TODO: Implement tokenize(text):\n",
    "# - Lowercase the text\n",
    "# - Remove punctuation using a regex (replace non-word, non-space with a space)\n",
    "# - Split into words and return a set of unique tokens\n",
    "def tokenize(text):\n",
    "    text = re.sub(r'[^\\w\\s]+', ' ', text)\n",
    "    text = text.lower().split()\n",
    "    return set(text)\n",
    "\n",
    "# TODO: Implement rag_retrieval(query, knowledge_base):\n",
    "# - Tokenize the query\n",
    "# - For each document in the knowledge base:\n",
    "#   - Tokenize doc[\"content\"]\n",
    "#   - Compute overlap size between query tokens and doc tokens\n",
    "# - Track the best document by highest overlap score\n",
    "# - Tie-break: if scores are equal and positive, choose the doc with smaller id\n",
    "# - Return the best document, or None if there is no overlap\n",
    "def rag_retrieval(query, knowledge_base):\n",
    "    query_words = tokenize(query)\n",
    "    best_doc = None\n",
    "    best_overlap = 0\n",
    "    best_id = 0\n",
    "    for doc in knowledge_base:\n",
    "        doc_words = tokenize(doc[\"content\"])\n",
    "        overlap = len(query_words & doc_words)\n",
    "        ids = doc[\"id\"]\n",
    "        if overlap > best_overlap:\n",
    "            best_overlap = overlap\n",
    "            best_doc = doc\n",
    "            best_id = ids\n",
    "        elif overlap == best_overlap:\n",
    "            if ids < best_id:\n",
    "                best_doc = doc\n",
    "                best_id = ids\n",
    "            \n",
    "    return best_doc if best_overlap > 0 else None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Implement build_prompt(user_prompt, rag_document=None):\n",
    "# - If rag_document is provided, return:\n",
    "#   \"Question: <user_prompt>\\nContext: <rag_document['content']>\\nAnswer:\"\n",
    "# - Otherwise, return the original user_prompt\n",
    "\n",
    "def build_prompt(user_prompt, rag_document=None):\n",
    "    \"\"\"\n",
    "    Build a prompt that lists retrieved notes under a Context section.\n",
    "    If no documents are provided, return the original question.\n",
    "    \"\"\"\n",
    "    if rag_document:\n",
    "        return f\"Question: {user_prompt}\\nContext: {rag_document['content']}\\nAnswer:\"\n",
    "    return user_prompt\n",
    "    \n",
    "    \n",
    "# TODO: Implement main():\n",
    "# - Load data from \"data.json\"\n",
    "# - Define a user query like: \"What should I focus on for SQL joins?\"\n",
    "# - Run rag_retrieval to get the best document\n",
    "# - Build the prompt with build_prompt\n",
    "# - Call ask_agent(prompt) and print the response\n",
    "def main():\n",
    "    data = load_data(\"data.json\")\n",
    "\n",
    "    query = \"How should I start tackling React useContext\"\n",
    "    top_k = 5\n",
    "\n",
    "    rag_documents = rag_retrieval(query, data)\n",
    "\n",
    "    prompt = build_prompt(query, rag_documents)\n",
    "\n",
    "    response = ask_agent(prompt)\n",
    "\n",
    "    print(response)\n",
    "\n",
    "\n",
    "# TODO: Add the standard Python entry point guard to call main():\n",
    "# if __name__ == '__main__':\n",
    "#     main()\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
