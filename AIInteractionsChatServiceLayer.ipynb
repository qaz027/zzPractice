{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ab72e77",
   "metadata": {},
   "source": [
    "# Lesson: Handling AI Interactions with the Chat Service Layer\n",
    "Handling AI Interactions with the Chat Service Layer\n",
    "\n",
    "In the previous lesson, we explored the ChatManager class, which plays a crucial role in managing chat data within our application. Now, we will take the next step in our journey by building the Chat Service Layer. This layer is essential for integrating the language model with chat sessions, allowing us to process user messages and generate AI responses. By the end of this lesson, you will understand how to set up the ChatService class, create chat sessions, and process messages using OpenAI's API.\n",
    "\n",
    "The service layer acts as a bridge between the model layer, where data is managed, and the AI model, which generates responses. It is responsible for orchestrating the flow of data and ensuring that user interactions are handled smoothly. Let's dive into the details of setting up this important component.\n",
    "Setting Up the ChatService Class\n",
    "\n",
    "The ChatService class is the heart of our service layer. It is responsible for managing chat sessions and interacting with the OpenAI client to generate AI responses. To begin, we need to set up the class and its components.\n",
    "\n",
    "First, we import the necessary modules, including the ChatManager from our previous lesson and the OpenAI client. We also use the uuid module to generate unique chat IDs. Here's how the class is initialized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63be60ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from openai import OpenAI\n",
    "from models.chat import ChatManager\n",
    "\n",
    "class ChatService:\n",
    "    def __init__(self):\n",
    "        self.chat_manager = ChatManager()\n",
    "        self.openai_client = OpenAI()\n",
    "        self.system_prompt = self.load_system_prompt('data/system_prompt.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b02e90",
   "metadata": {},
   "source": [
    "In this setup, we instantiate ChatManager to manage chat data, initialize the OpenAI client, and load the system_prompt using the load_system_prompt method, which we'll discuss next.\n",
    "Loading the System Prompt\n",
    "\n",
    "The system prompt is a crucial component that guides the AI's responses. It provides context and instructions for the AI, ensuring that it behaves in a manner consistent with our application's goals. In this section, we'll implement the load_system_prompt method to load the prompt from a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ae8728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_system_prompt(self, file_path: str) -> str:\n",
    "    \"\"\"Load the system prompt from file.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            return f.read()\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading system prompt: {e}\")\n",
    "        return \"You are a helpful assistant.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020e22c8",
   "metadata": {},
   "source": [
    "This method attempts to read the system prompt from a specified file path. If successful, it returns the prompt as a string. In case of an error, it prints an error message and returns a default prompt. This ensures that the application can continue functioning even if the file is missing or corrupted.\n",
    "Creating a New Chat Session\n",
    "\n",
    "Creating a new chat session is a fundamental task of the ChatService. The create_chat method is responsible for generating a unique chat ID and initializing a chat session using the ChatManager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5799344",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chat(self, user_id: str) -> str:\n",
    "    \"\"\"Create a new chat session.\"\"\"\n",
    "    chat_id = str(uuid.uuid4())\n",
    "    self.chat_manager.create_chat(user_id, chat_id, self.system_prompt)\n",
    "    return chat_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50622d7a",
   "metadata": {},
   "source": [
    "In this method, we generate a unique chat_id using the uuid module. We then call the create_chat method of ChatManager, passing the user_id, chat_id, and system_prompt. This initializes a new chat session, which is ready to receive messages.\n",
    "Processing User Messages\n",
    "\n",
    "The process_message method is where the magic happens. It processes user messages, interacts with the OpenAI client to generate AI responses, and updates the chat history. Below, we outline the steps involved in this process, followed by the corresponding code implementation:\n",
    "\n",
    "    Retrieve the chat using get_chat, and raise an error if the chat is not found.\n",
    "    Add the user's message to the chat history.\n",
    "    Send the conversation, including the system prompt and all messages, to the OpenAI client to generate a response.\n",
    "    Add the AI's response to the chat history and return it to the user.\n",
    "    Handle any errors with the AI client gracefully.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1ddc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_message(self, user_id: str, chat_id: str, message: str) -> str:\n",
    "    \"\"\"Process a user message and get AI response.\"\"\"\n",
    "    \n",
    "    # Step 1: Retrieve the chat\n",
    "    chat = self.chat_manager.get_chat(user_id, chat_id)\n",
    "    if not chat:\n",
    "        raise ValueError(\"Chat not found\")\n",
    "    \n",
    "    # Step 2: Add user message to chat history\n",
    "    self.chat_manager.add_message(user_id, chat_id, \"user\", message)\n",
    "    \n",
    "    try:\n",
    "        # Step 3: Get AI response\n",
    "        conversation = self.chat_manager.get_conversation(user_id, chat_id)\n",
    "        \n",
    "        response = self.openai_client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=conversation,\n",
    "            temperature=0.7,\n",
    "            max_tokens=500\n",
    "        )\n",
    "        \n",
    "        ai_message = response.choices[0].message.content\n",
    "        \n",
    "        # Step 4: Add AI response to chat history\n",
    "        self.chat_manager.add_message(user_id, chat_id, \"assistant\", ai_message)\n",
    "        \n",
    "        return ai_message\n",
    "        \n",
    "    except Exception as e:\n",
    "        # Step 5: Handle errors\n",
    "        raise RuntimeError(f\"Error getting AI response: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f189d9",
   "metadata": {},
   "source": [
    "In the context of a customer service agent, we configure our model with specific parameters to optimize its performance. The temperature is set to 0.7, which balances creativity and coherence in the AI's responses, ensuring they are both engaging and relevant. The max_tokens is set to 500, allowing the model to provide detailed and informative answers without overwhelming the user, thus maintaining a smooth and effective customer service experience.\n",
    "Example: Simulating a Chat Session\n",
    "\n",
    "Let's see the ChatService in action by simulating a chat session. We'll use the main.py file to create a chat session and process a user message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6d0ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from services.chat_service import ChatService\n",
    "\n",
    "# Initialize the chat service\n",
    "chat_service = ChatService()\n",
    "\n",
    "# Simulate a user ID\n",
    "user_id = \"user123\"\n",
    "\n",
    "# Create a new chat session\n",
    "chat_id = chat_service.create_chat(user_id)\n",
    "print(f\"Chat session created with ID: {chat_id}\")\n",
    "\n",
    "# Simulate sending a message\n",
    "user_message = \"Hello, how are you?\"\n",
    "\n",
    "try:\n",
    "    ai_response = chat_service.process_message(user_id, chat_id, user_message)\n",
    "    print(f\"AI Response: {ai_response}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7a4c8e",
   "metadata": {},
   "source": [
    "In this example, we initialize the ChatService, simulate a user ID, and create a new chat session, printing the chat ID. We then simulate sending a message and print the AI's response, demonstrating the flow from user input to AI response and showcasing the functionality of the ChatService."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9e8491",
   "metadata": {},
   "source": [
    "Chat session created with ID: 01a17870-8a4f-4b6f-a3ce-f04e1136d597\n",
    "AI Response: Hello! I'm here to help with any questions or concerns you might have regarding our IT services. How can I assist you today?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75184cc8",
   "metadata": {},
   "source": [
    "This output illustrates a successful interaction where a new chat session is created, and the AI responds to the user's greeting with a helpful message. The AI's response is tailored to assist with IT services, showcasing the system's ability to provide relevant and context-aware assistance.\n",
    "Summary and Next Steps\n",
    "\n",
    "In this lesson, we explored the ChatService class and its role in integrating the language model with chat sessions. We learned how to set up the class, load the system prompt, create chat sessions, and process user messages. The service layer is a vital component of our chatbot application, ensuring that user interactions are handled smoothly and efficiently.\n",
    "\n",
    "As you move on to the practice exercises, take the opportunity to experiment with the ChatService functionality. This hands-on practice will reinforce the concepts covered in this lesson and prepare you for the next steps in our course. Keep up the great work, and I look forward to seeing your progress!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e3f896",
   "metadata": {},
   "source": [
    "# exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e4b6ed",
   "metadata": {},
   "source": [
    "Let's begin by implementing the create_chat method within the ChatService class. This method is essential for generating a unique chat ID and initializing a chat session. Here's what you need to do:\n",
    "\n",
    "    Implement the create_chat method within the ChatService class.\n",
    "        Use the uuid module to generate a unique chat ID.\n",
    "        Utilize the ChatManager to create a chat session, associating it with the user ID, chat ID, and system prompt.\n",
    "        Ensure the method returns the generated chat ID.\n",
    "\n",
    "    Test the chat creation using the service.\n",
    "        Initialize an instance of ChatService.\n",
    "        Define a sample user ID to simulate a user.\n",
    "        Call the create_chat method with the user ID and store the returned chat ID.\n",
    "        Print the chat ID to verify the successful creation of the chat session.\n",
    "\n",
    "This task will guide you through the process of creating and managing chat sessions, a fundamental aspect of building a chatbot service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161ad706",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from openai import OpenAI\n",
    "from models.chat import ChatManager\n",
    "\n",
    "class ChatService:\n",
    "    def __init__(self):\n",
    "        # TODO: Initialize ChatManager to handle chat data\n",
    "        self.chat_manager = ChatManager()\n",
    "        self.system_prompt = self.load_system_prompt('data/system_prompt.txt')\n",
    "    \n",
    "    def load_system_prompt(self, file_path: str) -> str:\n",
    "        \"\"\"Load the system prompt from file.\"\"\"\n",
    "        try:\n",
    "            with open(file_path, 'r') as f:\n",
    "                return f.read()\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading system prompt: {e}\")\n",
    "            return \"You are a helpful assistant.\"\n",
    "    \n",
    "    # TODO: Define the create_chat method\n",
    "    def create_chat(self, user_id):\n",
    "    # - Parameters: user_id\n",
    "    # - Generate a unique chat ID using uuid\n",
    "        chat_id = str(uuid.uuid4())\n",
    "    # - Use chat_manager to create a chat session with user_id, chat_id, and system_prompt\n",
    "        self.chat_manager.create_chat(user_id, chat_id, self.system_prompt)\n",
    "    # - Return the chat_id\n",
    "        return chat_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf888934",
   "metadata": {},
   "outputs": [],
   "source": [
    "from services.chat_service import ChatService\n",
    "\n",
    "# TODO: Initialize a ChatService instance\n",
    "chat_service = ChatService()\n",
    "\n",
    "# TODO: Define a variable with a sample user identifier, e.g., \"user123\"\n",
    "user_id = \"user123\"\n",
    "# TODO: Call the create_chat method with the user ID and store the chat ID\n",
    "chat_id = chat_service.create_chat(user_id)\n",
    "\n",
    "# TODO: Print the chat ID\n",
    "print(f\"Chat session created with ID: {chat_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682c3a8f",
   "metadata": {},
   "source": [
    "Chat session created with ID: cb97abeb-85f5-496a-afe6-8fafe84f5a12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7547a3d2",
   "metadata": {},
   "source": [
    "You've done well setting up the ChatService class and creating chat sessions. Now, let's begin implementing the process_message method to handle user messages. For now, we will focus on storing the user's message without getting a response from the AI. Here's what you need to do:\n",
    "\n",
    "    Implement the process_message method within the ChatService class.\n",
    "        Check if the chat session exists using the get_chat method from ChatManager.\n",
    "            If the chat doesn't exist, raise a ValueError with the message \"Chat not found\".\n",
    "        Add the user's message to the chat history using the add_message method from ChatManager.\n",
    "        Return a string indicating the message was processed, e.g., \"Message processed\".\n",
    "\n",
    "    Test the process_message method by simulating a user message, ensuring the chat history is updated correctly, and handle any exceptions by printing them if the chat session does not exist.\n",
    "\n",
    "This task will ensure that your chat service can effectively handle user messages, setting the stage for integrating AI responses in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8795d15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from openai import OpenAI\n",
    "from models.chat import ChatManager\n",
    "\n",
    "class ChatService:\n",
    "    def __init__(self):\n",
    "        self.chat_manager = ChatManager()\n",
    "        self.system_prompt = self.load_system_prompt('data/system_prompt.txt')\n",
    "    \n",
    "    def load_system_prompt(self, file_path: str) -> str:\n",
    "        \"\"\"Load the system prompt from file.\"\"\"\n",
    "        try:\n",
    "            with open(file_path, 'r') as f:\n",
    "                return f.read()\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading system prompt: {e}\")\n",
    "            return \"You are a helpful assistant.\"\n",
    "    \n",
    "    def create_chat(self, user_id: str) -> str:\n",
    "        \"\"\"Create a new chat session.\"\"\"\n",
    "        chat_id = str(uuid.uuid4())\n",
    "        self.chat_manager.create_chat(user_id, chat_id, self.system_prompt)\n",
    "        return chat_id\n",
    "    \n",
    "    # TODO: Define the process_message method\n",
    "    def process_message(self, user_id, chat_id, message):\n",
    "    # - Parameters: user_id, chat_id, message\n",
    "    # - Check if the chat session exists using get_chat\n",
    "        chat = self.chat_manager.get_chat(user_id, chat_id)\n",
    "        if not chat:\n",
    "    #   - If the chat doesn't exist, raise a ValueError with \"Chat not found\"\n",
    "            raise ValueError(\"Chat not found\")\n",
    "    # - Add the user's message to the chat history using add_message\n",
    "        self.chat_manager.add_message(user_id, chat_id, \"user\", message)\n",
    "    # - Return a string indicating the message was processed\n",
    "        return \"message was processed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856cfa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from services.chat_service import ChatService\n",
    "\n",
    "# Initialize the chat service\n",
    "chat_service = ChatService()\n",
    "\n",
    "# Simulate a user ID\n",
    "user_id = \"user123\"\n",
    "\n",
    "# Create a new chat session\n",
    "chat_id = chat_service.create_chat(user_id)\n",
    "\n",
    "# TODO: Simulate sending a message and handle potential exceptions\n",
    "print(chat_service.process_message(user_id, chat_id, \"I am a new user and would like some assistance.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e1e80c",
   "metadata": {},
   "source": [
    "message was processed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c54b66",
   "metadata": {},
   "source": [
    "Nice work on setting up the process_message method! Now, let's enhance it to generate AI responses. Your task is to add the missing code that interacts with the OpenAI client to obtain the AI response and update the chat history.\n",
    "\n",
    "Here's what you need to do in the ChatService class:\n",
    "\n",
    "    Instantiate the OpenAI client to interact with the AI model.\n",
    "    Retrieve the conversation using get_conversation from ChatManager.\n",
    "    Use the OpenAI client to generate a response from \"gpt-4\" based on the conversation, set the temperature to 0.7 and the maximum tokens to 500 to balance creativity and coherence in responses.\n",
    "    Extract the AI's response from the OpenAI client response.\n",
    "    Add the AI's response to the chat history.\n",
    "    Return the AI's response.\n",
    "\n",
    "Remember to handle exceptions during the OpenAI client interaction by raising a RuntimeError with an appropriate message.\n",
    "\n",
    "The main code is pre-configured, allowing you to test the integration seamlessly. Keep going; you're doing well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5792ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from openai import OpenAI\n",
    "from models.chat import ChatManager\n",
    "\n",
    "class ChatService:\n",
    "    def __init__(self):\n",
    "        self.chat_manager = ChatManager()\n",
    "        # TODO: Initialize the OpenAI client to interact with the AI model\n",
    "        self.openai_client = OpenAI()\n",
    "        self.system_prompt = self.load_system_prompt('data/system_prompt.txt')\n",
    "    \n",
    "    def load_system_prompt(self, file_path: str) -> str:\n",
    "        \"\"\"Load the system prompt from file.\"\"\"\n",
    "        try:\n",
    "            with open(file_path, 'r') as f:\n",
    "                return f.read()\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading system prompt: {e}\")\n",
    "            return \"You are a helpful assistant.\"\n",
    "    \n",
    "    def create_chat(self, user_id: str) -> str:\n",
    "        \"\"\"Create a new chat session.\"\"\"\n",
    "        chat_id = str(uuid.uuid4())\n",
    "        self.chat_manager.create_chat(user_id, chat_id, self.system_prompt)\n",
    "        return chat_id\n",
    "    \n",
    "    def process_message(self, user_id: str, chat_id: str, message: str) -> str:\n",
    "        \"\"\"Process a user message and get AI response.\"\"\"\n",
    "        chat = self.chat_manager.get_chat(user_id, chat_id)\n",
    "        if not chat:\n",
    "            raise ValueError(\"Chat not found\")\n",
    "        \n",
    "        # Add user message\n",
    "        self.chat_manager.add_message(user_id, chat_id, \"user\", message)\n",
    "        \n",
    "        try:\n",
    "            # TODO: Retrieve the conversation using the ChatManager\n",
    "            conversation = self.chat_manager.get_conversation(user_id, chat_id)\n",
    "            # TODO: Use the OpenAI client to generate a response based on the conversation\n",
    "            # - Set the model to \"gpt-4\"\n",
    "            # - Pass the conversation as the messages parameter to provide context\n",
    "            # - Use a temperature of 0.7 to balance creativity and coherence in responses\n",
    "            # - Limit the response length to 500 tokens\n",
    "            response = self.openai_client.chat.completions.create(\n",
    "                model=\"gpt-4\",\n",
    "                messages=conversation,\n",
    "                temperature=0.7,\n",
    "                max_tokens=500\n",
    "                )\n",
    "            \n",
    "            # TODO: Extract the AI's response from the OpenAI client response\n",
    "            ai_message = response.choices[0].message.content\n",
    "            # TODO: Add the AI's response to the chat history\n",
    "            self.chat_manager.add_message(user_id, chat_id, \"assistant\", ai_message)\n",
    "            # TODO: Return the AI's response\n",
    "            return ai_message\n",
    "            \n",
    "        except Exception as e:\n",
    "            # TODO: Handle exceptions and raise a RuntimeError with an appropriate message\n",
    "            raise RuntimeError(f\"Error getting AI response: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece88471",
   "metadata": {},
   "outputs": [],
   "source": [
    "from services.chat_service import ChatService\n",
    "\n",
    "# Initialize the chat service\n",
    "chat_service = ChatService()\n",
    "\n",
    "# Simulate a user ID\n",
    "user_id = \"user123\"\n",
    "\n",
    "# Create a new chat session\n",
    "chat_id = chat_service.create_chat(user_id)\n",
    "print(f\"Chat session created with ID: {chat_id}\")\n",
    "\n",
    "# Simulate sending a message\n",
    "user_message = \"How can I contact your company by email?\"\n",
    "print(f\"User Message: {user_message}\")\n",
    "\n",
    "try:\n",
    "    ai_response = chat_service.process_message(user_id, chat_id, user_message)\n",
    "    print(f\"AI Response: {ai_response}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634a80dc",
   "metadata": {},
   "source": [
    "Chat session created with ID: c35c1413-cd01-43b3-8bd3-34108322457a\n",
    "User Message: How can I contact your company by email?\n",
    "AI Response: You can reach us by sending an email to support@techcaresolutions.com. Our customer service team will be glad to assist you with any questions or concerns you may have."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d53c404",
   "metadata": {},
   "source": [
    "You've successfully set up the chat service and processed the initial message. Now, let's enhance the AI's capability by testing its ability to retain context across multiple interactions. This will ensure the AI can handle multi-turn conversations effectively.\n",
    "\n",
    "Here's what you need to do:\n",
    "\n",
    "    After sending the initial message, define a follow-up question that requires the AI to recall the context of the previous message. For example, you might ask: \"Is there another way?\" Print this follow-up question to the console.\n",
    "\n",
    "    Use the process_message method to send this follow-up question to the AI.\n",
    "\n",
    "    Print the AI's response to the follow-up question to verify its ability to maintain context across multiple messages.\n",
    "\n",
    "This task will help you verify the AI's ability to maintain context across multiple messages. Keep going; you're doing well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506e3f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from openai import OpenAI\n",
    "from models.chat import ChatManager\n",
    "\n",
    "class ChatService:\n",
    "    def __init__(self):\n",
    "        self.chat_manager = ChatManager()\n",
    "        self.openai_client = OpenAI()\n",
    "        self.system_prompt = self.load_system_prompt('data/system_prompt.txt')\n",
    "    \n",
    "    def load_system_prompt(self, file_path: str) -> str:\n",
    "        \"\"\"Load the system prompt from file.\"\"\"\n",
    "        try:\n",
    "            with open(file_path, 'r') as f:\n",
    "                return f.read()\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading system prompt: {e}\")\n",
    "            return \"You are a helpful assistant.\"\n",
    "    \n",
    "    def create_chat(self, user_id: str) -> str:\n",
    "        \"\"\"Create a new chat session.\"\"\"\n",
    "        chat_id = str(uuid.uuid4())\n",
    "        self.chat_manager.create_chat(user_id, chat_id, self.system_prompt)\n",
    "        return chat_id\n",
    "    \n",
    "    def process_message(self, user_id: str, chat_id: str, message: str) -> str:\n",
    "        \"\"\"Process a user message and get AI response.\"\"\"\n",
    "        chat = self.chat_manager.get_chat(user_id, chat_id)\n",
    "        if not chat:\n",
    "            raise ValueError(\"Chat not found\")\n",
    "        \n",
    "        # Add user message\n",
    "        self.chat_manager.add_message(user_id, chat_id, \"user\", message)\n",
    "        \n",
    "        try:\n",
    "            # Get AI response\n",
    "            conversation = self.chat_manager.get_conversation(user_id, chat_id)\n",
    "            \n",
    "            response = self.openai_client.chat.completions.create(\n",
    "                model=\"gpt-4\",\n",
    "                messages=conversation,\n",
    "                temperature=0.7,\n",
    "                max_tokens=500\n",
    "            )\n",
    "            \n",
    "            ai_message = response.choices[0].message.content\n",
    "            \n",
    "            # Add AI response to chat history\n",
    "            self.chat_manager.add_message(user_id, chat_id, \"assistant\", ai_message)\n",
    "            \n",
    "            return ai_message\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Error getting AI response: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c8eaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from services.chat_service import ChatService\n",
    "\n",
    "# Initialize the chat service\n",
    "chat_service = ChatService()\n",
    "\n",
    "# Simulate a user ID\n",
    "user_id = \"user123\"\n",
    "\n",
    "# Create a new chat session\n",
    "chat_id = chat_service.create_chat(user_id)\n",
    "print(f\"Chat session created with ID: {chat_id}\")\n",
    "\n",
    "# Define a user message\n",
    "user_message = \"How can I contact your company by email?\"\n",
    "print(f\"User Message: {user_message}\")\n",
    "\n",
    "try:\n",
    "    ai_response = chat_service.process_message(user_id, chat_id, user_message)\n",
    "    print(f\"AI Response: {ai_response}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "# TODO: Define and print a follow-up question\n",
    "user_followup = \"Is there another way I can contact the company?\"\n",
    "# TODO: Send the follow-up question to test context retention\n",
    "\n",
    "# TODO: Print the AI's response to the follow-up question\n",
    "try:\n",
    "    ai_response2 = chat_service.process_message(user_id, chat_id, user_followup)\n",
    "    print(f\"AI Response: {ai_response2}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e621de",
   "metadata": {},
   "source": [
    "Chat session created with ID: 697e8385-90fb-454f-8713-b258340781f1\n",
    "User Message: How can I contact your company by email?\n",
    "AI Response: You can reach us via email at support@techcaresolutions.com. We're here to assist you with any inquiry or concern you might have.\n",
    "AI Response: Yes, you can also reach us by phone. Our customer service number is 1-800-TECHCARE. We're available to help with your inquiries or concerns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefa73a7",
   "metadata": {},
   "source": [
    "You've made great progress in setting up the ChatService class and processing user messages. Now, let's focus on creating multiple chat sessions for the same user to ensure that each session has a cleared context.\n",
    "\n",
    "Here's what you need to do:\n",
    "\n",
    "    Create a Second Chat Session: Use the create_chat method to create a new chat session for the same user. This will ensure that the user can have multiple independent conversations.\n",
    "\n",
    "    Process a Message in the Second Chat: Simulate sending a message in the newly created chat session using the process_message method. This will test that the chat session is functioning correctly and independently from the first session.\n",
    "\n",
    "This task will guide you through the process of creating and managing chat sessions, a fundamental aspect of building a chatbot service. Keep up the momentum!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08f0d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from openai import OpenAI\n",
    "from models.chat import ChatManager\n",
    "\n",
    "class ChatService:\n",
    "    def __init__(self):\n",
    "        self.chat_manager = ChatManager()\n",
    "        self.openai_client = OpenAI()\n",
    "        self.system_prompt = self.load_system_prompt('data/system_prompt.txt')\n",
    "    \n",
    "    def load_system_prompt(self, file_path: str) -> str:\n",
    "        \"\"\"Load the system prompt from file.\"\"\"\n",
    "        try:\n",
    "            with open(file_path, 'r') as f:\n",
    "                return f.read()\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading system prompt: {e}\")\n",
    "            return \"You are a helpful assistant.\"\n",
    "    \n",
    "    def create_chat(self, user_id: str) -> str:\n",
    "        \"\"\"Create a new chat session.\"\"\"\n",
    "        chat_id = str(uuid.uuid4())\n",
    "        self.chat_manager.create_chat(user_id, chat_id, self.system_prompt)\n",
    "        return chat_id\n",
    "    \n",
    "    def process_message(self, user_id: str, chat_id: str, message: str) -> str:\n",
    "        \"\"\"Process a user message and get AI response.\"\"\"\n",
    "        chat = self.chat_manager.get_chat(user_id, chat_id)\n",
    "        if not chat:\n",
    "            raise ValueError(\"Chat not found\")\n",
    "        \n",
    "        # Add user message\n",
    "        self.chat_manager.add_message(user_id, chat_id, \"user\", message)\n",
    "        \n",
    "        try:\n",
    "            # Get AI response\n",
    "            conversation = self.chat_manager.get_conversation(user_id, chat_id)\n",
    "            \n",
    "            response = self.openai_client.chat.completions.create(\n",
    "                model=\"gpt-4\",\n",
    "                messages=conversation,\n",
    "                temperature=0.7,\n",
    "                max_tokens=500\n",
    "            )\n",
    "            \n",
    "            ai_message = response.choices[0].message.content\n",
    "            \n",
    "            # Add AI response to chat history\n",
    "            self.chat_manager.add_message(user_id, chat_id, \"assistant\", ai_message)\n",
    "            \n",
    "            return ai_message\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Error getting AI response: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c2844a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from services.chat_service import ChatService\n",
    "\n",
    "# Initialize the chat service\n",
    "chat_service = ChatService()\n",
    "\n",
    "# Simulate a user ID\n",
    "user_id = \"user123\"\n",
    "\n",
    "# Create a new chat session\n",
    "chat_id = chat_service.create_chat(user_id)\n",
    "print(f\"Chat session created with ID: {chat_id}\")\n",
    "\n",
    "# Simulate sending a message\n",
    "user_message = \"Hello, how are you?\"\n",
    "\n",
    "try:\n",
    "    ai_response = chat_service.process_message(user_id, chat_id, user_message)\n",
    "    print(f\"AI Response: {ai_response}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "# TODO: Create a second chat session for the same user and process a new message\n",
    "chat_id2 = chat_service.create_chat(user_id)\n",
    "print(f\"Chat session created with ID: {chat_id2}\")\n",
    "user_message2 = \"I sent an earlier message saying hi but I started a second chat to ask about returns. I'm not happy with the product I bought.\"\n",
    "\n",
    "try:\n",
    "    ai_response2 = chat_service.process_message(user_id, chat_id2, user_message2)\n",
    "    print(f\"AI Response: {ai_response2}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e47c6e",
   "metadata": {},
   "source": [
    "Chat session created with ID: a2f8a074-0842-4df1-89ca-696409c44ee7\n",
    "AI Response: Hello! I'm doing well, thank you. How can I assist you with your TechCare Solutions needs today?\n",
    "Chat session created with ID: 783747fe-d147-4105-badf-eba0a7e4e983\n",
    "AI Response: I'm really sorry to hear that you're not satisfied with the product you've purchased. As a customer service representative, I'm unable to process refunds directly. However, I can definitely guide you on how to proceed. You'll need to contact our billing department. They can assist you with your refund request. You can reach them at 1-800-TECHCARE or you can send an email to support@techcaresolutions.com. Please provide them with your account information and details about the product you're not satisfied with. They'll be able to help you from there."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
