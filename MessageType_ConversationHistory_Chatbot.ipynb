{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "474969a4",
   "metadata": {},
   "source": [
    "# Lesson: Message Types and Conversation History\n",
    "Message Types and Conversation History\n",
    "\n",
    "Welcome back! In the previous lessons, you learned how to send a simple message to OpenAI's language model and explored various model parameters to customize the AI's responses. Now, we will delve into the concept of message types and the importance of maintaining conversation history. These elements are crucial for creating dynamic and context-aware interactions with the AI, allowing your chatbot to engage in more meaningful conversations.\n",
    "Understanding Message Types\n",
    "\n",
    "Before we dive into building and managing conversation history, it’s important to understand the concept of message types and how a conversation history is structured. In a chatbot interaction, messages are typically categorized by roles officially recognized by OpenAI: \"system\", \"user\", and \"assistant\". While we’ll explore system prompts more thoroughly in a later lesson, remember that these primary roles help define the flow of dialogue and ensure the AI understands who is speaking at any given time. You can technically specify other roles, but doing so may produce unpredictable results because they are not officially supported by OpenAI’s chat completion API.\n",
    "\n",
    "OpenAI expects the conversation history to be formatted as a list of dictionaries, where each dictionary represents a message with two key-value pairs: \"role\" and \"content\". Here’s an example of what a simple conversation history might look like:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59dcb6d6",
   "metadata": {},
   "source": [
    "```json\n",
    "[\n",
    "    {\"role\": \"user\", \"content\": \"Can you recommend a good book?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"I recommend 'To Kill a Mockingbird' by Harper Lee.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What's it about?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"It's a novel about racial injustice and moral growth in the American South.\"}\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5ae6c2",
   "metadata": {},
   "source": [
    "In this example, the conversation history consists of alternating messages between the user (the person interacting with the AI) and the assistant (the AI itself). Each message is stored with its respective role, providing context for the AI to generate appropriate responses. Understanding this structure is key to effectively managing conversations and ensuring that the AI can engage in more meaningful interactions.\n",
    "Creating a Function to Handle Conversations\n",
    "\n",
    "To manage conversations effectively, we will create a function called send_message. This function will send messages to the AI and receive responses, allowing us to handle multiple interactions seamlessly. Here's how the function is structured:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5c1d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "# Function to send a message and receive a response\n",
    "def send_message(messages):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=messages\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4c2841",
   "metadata": {},
   "source": [
    "In this function, we use the chat.completions.create method to send a list of messages to the AI. The messages parameter contains the conversation history, which provides context for the AI's response. The function returns the AI's response, which is extracted from the API result and stripped of any leading or trailing whitespace.\n",
    "Building and Managing Conversation History\n",
    "\n",
    "Maintaining a conversation history is crucial for providing context to the AI. This allows the AI to generate responses that are relevant to the ongoing dialogue. Let's see how we can build and manage conversation history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8085f929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a conversation history with an initial message\n",
    "conversation = [\n",
    "    {\"role\": \"user\", \"content\": \"What's the capital of France?\"}\n",
    "]\n",
    "\n",
    "# Get first response\n",
    "reply = send_message(conversation)\n",
    "print(\"Assistant:\", reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46c1907",
   "metadata": {},
   "source": [
    "After sending the initial message, the AI responds with the capital of France, showcasing its ability to provide factual information:\n",
    "\n",
    "    Assistant: The capital of France is Paris.\n",
    "\n",
    "In this example, we start a conversation with an initial message from the user. The send_message function is used to get the AI's response, which is then printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab956773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the assistant's response to conversation history\n",
    "conversation.append({\"role\": \"assistant\", \"content\": reply})\n",
    "\n",
    "# Add a follow-up question\n",
    "conversation.append({\"role\": \"user\", \"content\": \"Is it a large city?\"})\n",
    "\n",
    "# Get response with conversation context\n",
    "follow_up_reply = send_message(conversation)\n",
    "print(\"Assistant follow-up:\", follow_up_reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525ab32e",
   "metadata": {},
   "source": [
    "With the conversation history maintained, the AI provides a contextually relevant follow-up response, confirming the size of the city:\n",
    "\n",
    "    Assistant follow-up: Yes, Paris is a large city.\n",
    "\n",
    "By maintaining this history, we provide context for subsequent interactions, allowing the AI to generate more coherent and relevant responses.\n",
    "Visualizing the Conversation History\n",
    "\n",
    "To better understand how the conversation has evolved, we can print the entire conversation history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9a79ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the entire conversation history\n",
    "for message in conversation:\n",
    "    print(f\"{message['role'].capitalize()}: {message['content']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff3e19a",
   "metadata": {},
   "source": [
    "This will output the complete dialogue, showing both user inputs and AI responses:\n",
    "\n",
    "    User: What's the capital of France?\n",
    "    Assistant: The capital of France is Paris.\n",
    "    User: Is it a large city?\n",
    "    Assistant: Yes, Paris is a large city.\n",
    "\n",
    "Having access to the conversation history allows you to track the flow of dialogue and ensure that the AI's responses remain contextually relevant.\n",
    "Summary and Preparation for Practice\n",
    "\n",
    "In this lesson, you learned about message types and the importance of maintaining conversation history in chatbot interactions. We explored how to set up your environment, initialize the OpenAI client, and create a function to handle conversations. You also saw how to build and manage conversation history, enabling the AI to generate contextually relevant responses.\n",
    "\n",
    "As you move on to the practice exercises, I encourage you to experiment with different conversation scenarios and observe how the AI's responses change based on the context provided. This hands-on practice will reinforce what you've learned and prepare you for the next unit, where we'll continue to build on these concepts. Keep up the great work, and enjoy the journey of creating your chatbot with OpenAI!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7c36bc",
   "metadata": {},
   "source": [
    "Great job on understanding how to manage conversation history! Now, let's put that knowledge into practice.\n",
    "\n",
    "Your task is to start the initial conversation history by adding a single dictionary to the list. This dictionary should have:\n",
    "\n",
    "    A \"role\" of \"user\"\n",
    "    A \"content\" containing the user's message\n",
    "\n",
    "Ensure it is correctly formatted for use with the send_message function. Dive in and see how smoothly you can get the AI to respond!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c3a043",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "# Function to send a message and receive a response\n",
    "def send_message(messages):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=messages\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "# TODO: Start a conversation history with an initial message\n",
    "conversation = [\n",
    "    # Add your initial user message here\n",
    "    {\"role\":\"user\",\n",
    "    \"content\": \"Who said Don't fake the funk on a nasty dunk?\"}\n",
    "]\n",
    "\n",
    "# Get first response\n",
    "reply = send_message(conversation)\n",
    "print(\"Assistant:\", reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83275a43",
   "metadata": {},
   "source": [
    "Assistant: Shaquille O'Neal said \"Don't fake the funk on a nasty dunk.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cfa6bb",
   "metadata": {},
   "source": [
    "Well done on learning about message types and conversation history! Now, let's apply that knowledge.\n",
    "\n",
    "Your task is to pass the initial conversation history to the send_message function. Follow these steps:\n",
    "\n",
    "    Call the send_message function passing the conversation list to get the assistant's response.\n",
    "    Store the response in a variable.\n",
    "    Print the variable to see how the AI replies.\n",
    "\n",
    "This exercise will help you see the AI in action. Enjoy the process!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856e5c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "# Function to send a message and receive a response\n",
    "def send_message(messages):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=messages\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "# Start a conversation history with an initial message\n",
    "conversation = [\n",
    "    {\"role\": \"user\", \"content\": \"Can you tell me a fun fact about space?\"}\n",
    "]\n",
    "\n",
    "# TODO: Pass the conversation to send_message and store the response in a variable\n",
    "reply = send_message(conversation)\n",
    "\n",
    "# TODO: Print the assistant's response\n",
    "print(\"Assistant:\", reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe6e9d0",
   "metadata": {},
   "source": [
    "Assistant: Yes, sure! Did you know that the footprints left by astronauts on the moon will stay there for at least 100 million years? This is because the moon has no atmosphere and therefore no wind or water to erode or wash away these marks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd16ff8",
   "metadata": {},
   "source": [
    "Nice work on the previous exercise! Now, let's build on that by adding more depth to our conversation.\n",
    "\n",
    "Your task is to:\n",
    "\n",
    "    Append the assistant's initial response to the conversation history.\n",
    "    Append a new user message with a follow-up question.\n",
    "    Use the send_message function with the updated conversation history to get and print the assistant's response.\n",
    "\n",
    "This will show you how the AI uses conversation context. Dive in and see the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7a94f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "# Function to send a message and receive a response\n",
    "def send_message(messages):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=messages\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "# Start a conversation history with an initial message\n",
    "conversation = [\n",
    "    {\"role\": \"user\", \"content\": \"Can you tell me a fun fact about space?\"}\n",
    "]\n",
    "\n",
    "# Get first response\n",
    "reply = send_message(conversation)\n",
    "print(\"Assistant:\", reply)\n",
    "\n",
    "# TODO: Append the assistant's response to conversation history\n",
    "conversation.append({\"role\":\"assistant\", \"content\": reply})\n",
    "\n",
    "# TODO: Append a follow-up question to conversation history\n",
    "conversation.append({\"role\": \"user\", \"content\": \"How fast would radio waves travel in space and how does that compare with the speed of radio waves on earth?\"})\n",
    "\n",
    "# TODO: Call send_message with the updated conversation history and print the response\n",
    "follow_up_reply = send_message(conversation)\n",
    "print(\"Assistant follow-up:\", follow_up_reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03208b3",
   "metadata": {},
   "source": [
    "Assistant: Absolutely! Did you know that a day on Venus is longer than a year on Venus? It takes 243 Earth days for Venus to rotate once on its axis (its day), while it only takes 225 Earth days for Venus to orbit the sun (its year).\n",
    "Assistant follow-up: Radio waves, like all forms of electromagnetic radiation, travel at the speed of light. The speed of light is approximately 299,792 kilometers per second or about 186,282 miles per second.\n",
    "\n",
    "In space, these waves can continue at this speed almost indefinitely (or until they hit an obstacle). \n",
    "\n",
    "On Earth, the speed of radio waves can be affected slightly by factors such as the medium they're passing through (air, water, etc.), due to refraction, diffraction, and interference. However, in practical communication applications, these effects are minimal and thus radio waves essentially still travel at the speed of light."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd70829f",
   "metadata": {},
   "source": [
    "Assistant: Absolutely! Did you know that space is completely silent? That's because sound needs a medium, like air or water, to travel through. In the emptiness of space, there is no air or other medium, so sound can't travel and we experience silence. That's why astronauts use radios to communicate while in space.\n",
    "Assistant follow-up: Radio waves are a type of electromagnetic radiation, just like light waves. In the vacuum of space, they travel at the speed of light, which is approximately 299,792 kilometers per second. On Earth, the speed of radio waves is also the speed of light. The presence of a medium like air doesn't significantly slow them down. So, radio waves travel at essentially the same speed in both space and on Earth. It's one of the reasons we can receive signals from spacecraft millions or even billions of kilometers away."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068dc076",
   "metadata": {},
   "source": [
    "You've done well in understanding how to manage conversation history! Now, let's put that knowledge into practice by visualizing the entire dialogue.\n",
    "\n",
    "Your task is to iterate over the conversation history and print each message. Make sure to display both the role and content of each message. This will help you see the flow of the conversation between the user and the assistant.\n",
    "\n",
    "Jump in and see how the conversation unfolds!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd57ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "# Function to send a message and receive a response\n",
    "def send_message(messages):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=messages\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "# Start a conversation history with an initial message\n",
    "conversation = [\n",
    "    {\"role\": \"user\", \"content\": \"What is the biggest planet in the solar system?\"}\n",
    "]\n",
    "\n",
    "# Get first response\n",
    "reply = send_message(conversation)\n",
    "\n",
    "# Add the assistant's response to conversation history\n",
    "conversation.append({\"role\": \"assistant\", \"content\": reply})\n",
    "\n",
    "# Add a follow-up question\n",
    "conversation.append({\"role\": \"user\", \"content\": \"What is its mass?\"})\n",
    "\n",
    "# Get response with conversation context\n",
    "follow_up_reply = send_message(conversation)\n",
    "\n",
    "# Add the follow-up response to conversation history\n",
    "conversation.append({\"role\": \"assistant\", \"content\": follow_up_reply})\n",
    "\n",
    "# TODO: Iterate over the conversation history and print each message\n",
    "for message in conversation:\n",
    "    print(f\"{message['role'].capitalize()}:{message['content']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dc20ed",
   "metadata": {},
   "source": [
    "User:What is the biggest planet in the solar system?\n",
    "Assistant:The biggest planet in the solar system is Jupiter.\n",
    "User:What is its mass?\n",
    "Assistant:Jupiter's mass is approximately 1.898 x 10^27 kilograms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4fc799",
   "metadata": {},
   "source": [
    "Great progress on understanding conversation history! Now, let's enhance the send_message function to make our code more efficient.\n",
    "\n",
    "Your task is to modify the function so that it:\n",
    "\n",
    "    Accepts a user message as a string.\n",
    "    Automatically appends the user message to the conversation history.\n",
    "    Sends the updated conversation to the AI.\n",
    "    Appends the AI's response to the conversation history.\n",
    "    Returns the AI's response as a string.\n",
    "\n",
    "When implementing this task, initialize the conversation history as an empty list. Ensure that only the send_message function appends new items, and avoid appending to the conversation history outside the function to maintain organized and manageable code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd6b5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "# Function to send a message and receive a response\n",
    "def send_message(messages):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=messages\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "# Start a conversation history with an initial message\n",
    "conversation = [\n",
    "    {\"role\": \"user\", \"content\": \"What is the main ingredient in guacamole?\"}\n",
    "]\n",
    "\n",
    "# Get first response\n",
    "reply = send_message(conversation)\n",
    "print(\"Assistant:\", reply)\n",
    "\n",
    "# Add the assistant's response to conversation history\n",
    "conversation.append({\"role\": \"assistant\", \"content\": reply})\n",
    "\n",
    "# Add a follow-up question\n",
    "conversation.append({\"role\": \"user\", \"content\": \"Can you name a popular dish that uses guacamole?\"})\n",
    "\n",
    "# Get response with conversation context\n",
    "follow_up_reply = send_message(conversation)\n",
    "print(\"Assistant follow-up:\", follow_up_reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e1856f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "# initialize conversation history as empty list\n",
    "conversation = []\n",
    "\n",
    "# Function to send a message and receive a response\n",
    "def send_message(conversation, messages):\n",
    "    conversation.append({\"role\": \"user\", \"content\": messages})\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=conversation\n",
    "    )\n",
    "    # append AI response to conversation history\n",
    "    #print(\"Assistant:\", response.choices[0].message.content.strip())\n",
    "    \n",
    "    conversation.append({\"role\": \"assistant\", \"content\": response.choices[0].message.content.strip()})\n",
    "    \n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "# Start a conversation history with an initial message\n",
    "conversation = [\n",
    "    {\"role\": \"user\", \"content\": \"What is the main ingredient in guacamole?\"}\n",
    "]\n",
    "\n",
    "reply = send_message(conversation, \"What is the main ingredient in guacamole?\")\n",
    "\n",
    "# Get first response\n",
    "#reply = send_message(conversation)\n",
    "print(\"Assistant:\", reply)\n",
    "\n",
    "# Add the assistant's response to conversation history\n",
    "#conversation.append({\"role\": \"assistant\", \"content\": reply})\n",
    "\n",
    "# Add a follow-up question\n",
    "# move append to send_message function\n",
    "#conversation.append({\"role\": \"user\", \"content\": \"Can you name a popular dish that uses guacamole?\"})\n",
    "\n",
    "# Get response with conversation context\n",
    "follow_up_reply = send_message(conversation,\"Can you name a popular dish that uses guacamole?\")\n",
    "print(\"Assistant follow-up:\", follow_up_reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c21e7aad",
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mopenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Initialize the OpenAI client\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# initialize conversation history as empty list\u001b[39;00m\n\u001b[1;32m      7\u001b[0m conversation \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/_client.py:130\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[0;34m(self, api_key, organization, project, webhook_secret, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m    128\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[1;32m    131\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    132\u001b[0m     )\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m api_key\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m organization \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "# initialize conversation history as empty list\n",
    "conversation = []\n",
    "\n",
    "# Function to send a message and receive a response\n",
    "def send_message(conversation, messages):\n",
    "    conversation.append({\"role\": \"user\", \"content\": messages})\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=conversation\n",
    "    )\n",
    "    \n",
    "    conversation.append({\"role\": \"assistant\", \"content\": response.choices[0].message.content.strip()})\n",
    "    \n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "# Start a conversation history with an initial message\n",
    "\n",
    "reply = send_message(conversation, \"What is the main ingredient in guacamole?\")\n",
    "\n",
    "# Get first response\n",
    "print(\"Assistant:\", reply)\n",
    "\n",
    "# Get response with conversation context\n",
    "follow_up_reply = send_message(conversation,\"Can you name a popular dish that uses guacamole?\")\n",
    "print(\"Assistant follow-up:\", follow_up_reply)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
